[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Dr. Uwe Remer",
    "section": "",
    "text": "Institut für Sozialwissenschaften Computational Social Science (CSS-Lab) Universität Stuttgart Seidenstraße 36 70174 Stuttgart Deutschland +49 711 685-83548 uwe.remer@sowi.uni-stuttgart.de"
  },
  {
    "objectID": "datenschutz.html",
    "href": "datenschutz.html",
    "title": "Datenschutzerklärung",
    "section": "",
    "text": "Auf dieser Seite erhalten Sie über Art, Umfang und Zwecke der Erhebung und Verwendung personenbezogener Daten dieser Webseite.\nEs wird keine Verantwortung für die Inhalte oder für die Privacy Policies von externen Ressourcen übernommen."
  },
  {
    "objectID": "datenschutz.html#beschreibung-und-umfang-der-datenverarbeitung",
    "href": "datenschutz.html#beschreibung-und-umfang-der-datenverarbeitung",
    "title": "Datenschutzerklärung",
    "section": "1. Beschreibung und Umfang der Datenverarbeitung",
    "text": "1. Beschreibung und Umfang der Datenverarbeitung\nDie Kontaktaufnahme ist über die bereitgestellte E-Mail-Adresse möglich. In diesem Fall werden die mit der E-Mail übermittelten personenbezogenen Daten des Nutzers gespeichert. Es erfolgt in diesem Zusammenhang keine Weitergabe der Daten an Dritte. Die Daten werden ausschließlich für die Verarbeitung der Konversation verwendet."
  },
  {
    "objectID": "datenschutz.html#rechtsgrundlage-für-die-datenverarbeitung",
    "href": "datenschutz.html#rechtsgrundlage-für-die-datenverarbeitung",
    "title": "Datenschutzerklärung",
    "section": "2. Rechtsgrundlage für die Datenverarbeitung",
    "text": "2. Rechtsgrundlage für die Datenverarbeitung\nRechtsgrundlage für die Verarbeitung der Daten, die im Zuge einer übersendung einer E-Mail übermittelt werden, ist Art. 6 Abs. 1 lit. f DSGVO."
  },
  {
    "objectID": "datenschutz.html#zweck-der-datenverarbeitung",
    "href": "datenschutz.html#zweck-der-datenverarbeitung",
    "title": "Datenschutzerklärung",
    "section": "3. Zweck der Datenverarbeitung",
    "text": "3. Zweck der Datenverarbeitung\nIm Falle einer Kontaktaufnahme per E-Mail liegt eben darin das erforderliche berechtigte Interesse an der Verarbeitung der Daten."
  },
  {
    "objectID": "datenschutz.html#dauer-der-speicherung",
    "href": "datenschutz.html#dauer-der-speicherung",
    "title": "Datenschutzerklärung",
    "section": "4. Dauer der Speicherung",
    "text": "4. Dauer der Speicherung\nDie Daten werden gelöscht, sobald sie für die Erreichung des Zweckes ihrer Erhebung nicht mehr erforderlich sind. Für die personenbezogenen Daten die per E-Mail übersandt wurden, ist dies dann der Fall, wenn die jeweilige Konversation mit dem Nutzer beendet ist. Beendet ist die Konversation dann, wenn sich aus den Umständen entnehmen lässt, dass der betroffene Sachverhalt abschließend geklärt ist."
  },
  {
    "objectID": "datenschutz.html#widerspruchs--und-beseitigungsmöglichkeit",
    "href": "datenschutz.html#widerspruchs--und-beseitigungsmöglichkeit",
    "title": "Datenschutzerklärung",
    "section": "5. Widerspruchs- und Beseitigungsmöglichkeit",
    "text": "5. Widerspruchs- und Beseitigungsmöglichkeit\nNimmt der Nutzer per E-Mail Kontakt mit uns auf, so kann er auf dem selben Weg der Speicherung seiner personenbezogenen Daten jederzeit widersprechen. In einem solchen Fall kann die Konversation nicht fortgeführt werden. Alle personenbezogenen Daten, die im Zuge der Kontaktaufnahme gespeichert wurden, werden in diesem Fall gelöscht."
  },
  {
    "objectID": "datenschutz.html#auskunftsrecht",
    "href": "datenschutz.html#auskunftsrecht",
    "title": "Datenschutzerklärung",
    "section": "1. Auskunftsrecht",
    "text": "1. Auskunftsrecht\nSie können von dem Verantwortlichen eine Bestätigung darüber verlangen, ob personenbezogene Daten, die Sie betreffen, von uns verarbeitet werden. Liegt eine solche Verarbeitung vor, können Sie von dem Verantwortlichen über folgende Informationen Auskunft verlangen:\n\ndie Zwecke, zu denen die personenbezogenen Daten verarbeitet werden;\ndie Kategorien von personenbezogenen Daten, welche verarbeitet werden;\ndie Empfänger bzw. die Kategorien von Empfängern, gegenüber denen die Sie betreffenden personenbezogenen Daten offengelegt wurden oder noch offengelegt werden;\ndie geplante Dauer der Speicherung der Sie betreffenden personenbezogenen Daten oder, falls konkrete Angaben hierzu nicht möglich sind, Kriterien für die Festlegung der Speicherdauer;\ndas Bestehen eines Rechts auf Berichtigung oder Löschung der Sie betreffenden personenbezogenen Daten, eines Rechts auf Einschränkung der Verarbeitung durch den Verantwortlichen oder eines Widerspruchsrechts gegen diese Verarbeitung;\ndas Bestehen eines Beschwerderechts bei einer Aufsichtsbehörde;\nalle verfügbaren Informationen über die Herkunft der Daten, wenn die personenbezogenen Daten nicht bei der betroffenen Person erhoben werden;\ndas Bestehen einer automatisierten Entscheidungsfindung einschließlich Profiling gemäß Art. 22 Abs. 1 und 4 DSGVO und - zumindest in diesen Fällen - aussagekräftige Informationen über die involvierte Logik sowie die Tragweite und die angestrebten Auswirkungen einer derartigen Verarbeitung für die betroffene Person.\n\nIhnen steht das Recht zu, Auskunft darüber zu verlangen, ob die Sie betreffenden personenbezogenen Daten in ein Drittland oder an eine internationale Organisation übermittelt werden. In diesem Zusammenhang können Sie verlangen, über die geeigneten Garantien gem. Art. 46 DSGVO im Zusammenhang mit der Übermittlung unterrichtet zu werden.\nDieses Auskunftsrecht kann insoweit beschränkt werden, als es voraussichtlich die Verwirklichung der Forschungs- oder Statistikzwecke unmöglich macht oder ernsthaft beeinträchtigt und die Beschränkung für die Erfüllung der Forschungs- oder Statistikzwecke notwendig ist."
  },
  {
    "objectID": "datenschutz.html#recht-auf-berichtigung",
    "href": "datenschutz.html#recht-auf-berichtigung",
    "title": "Datenschutzerklärung",
    "section": "2. Recht auf Berichtigung",
    "text": "2. Recht auf Berichtigung\nSie haben ein Recht auf Berichtigung und/oder Vervollständigung gegenüber dem Verantwortlichen, sofern die verarbeiteten personenbezogenen Daten, die Sie betreffen, unrichtig oder unvollständig sind. Der Verantwortliche hat die Berichtigung unverzüglich vorzunehmen.\nIhr Recht auf Berichtigung kann insoweit beschränkt werden, als es voraussichtlich die Verwirklichung der Forschungs- oder Statistikzwecke unmöglich macht oder ernsthaft beeinträchtigt und die Beschränkung für die Erfüllung der Forschungs- oder Statistikzwecke notwendig ist."
  },
  {
    "objectID": "datenschutz.html#recht-auf-einschränkung-der-verarbeitung",
    "href": "datenschutz.html#recht-auf-einschränkung-der-verarbeitung",
    "title": "Datenschutzerklärung",
    "section": "3. Recht auf Einschränkung der Verarbeitung",
    "text": "3. Recht auf Einschränkung der Verarbeitung\nUnter den folgenden Voraussetzungen können Sie die Einschränkung der Verarbeitung der Sie betreffenden personenbezogenen Daten verlangen:\n\nwenn Sie die Richtigkeit der Sie betreffenden personenbezogenen für eine Dauer bestreiten, die es dem Verantwortlichen ermöglicht, die Richtigkeit der personenbezogenen Daten zu überprüfen;\ndie Verarbeitung unrechtmäßig ist und Sie die Löschung der personenbezogenen Daten ablehnen und stattdessen die Einschränkung der Nutzung der personenbezogenen Daten verlangen;\nder Verantwortliche die personenbezogenen Daten für die Zwecke der Verarbeitung nicht länger benötigt, Sie diese jedoch zur Geltendmachung, Ausübung oder Verteidigung von Rechtsansprüchen benötigen, oder\nwenn Sie Widerspruch gegen die Verarbeitung gemäß Art. 21 Abs. 1 DSGVO eingelegt haben und noch nicht feststeht, ob die berechtigten Gründe des Verantwortlichen gegenüber Ihren Gründen überwiegen.\n\nWurde die Verarbeitung der Sie betreffenden personenbezogenen Daten eingeschränkt, dürfen diese Daten - von ihrer Speicherung abgesehen - nur mit Ihrer Einwilligung oder zur Geltendmachung, Ausübung oder Verteidigung von Rechtsansprüchen oder zum Schutz der Rechte einer anderen natürlichen oder juristischen Person oder aus Gründen eines wichtigen öffentlichen Interesses der Union oder eines Mitgliedstaates verarbeitet werden.\nWurde die Einschränkung der Verarbeitung nach den o.g. Voraussetzungen eingeschränkt, werden Sie von dem Verantwortlichen unterrichtet bevor die Einschränkung aufgehoben wird.\nIhr Recht auf Einschränkung der Verarbeitung kann insoweit beschränkt werden, als es voraussichtlich die Verwirklichung der Forschungs- oder Statistikzwecke unmöglich macht oder ernsthaft beeinträchtigt und die Beschränkung für die Erfüllung der Forschungs- oder Statistikzwecke notwendig ist."
  },
  {
    "objectID": "datenschutz.html#recht-auf-löschung",
    "href": "datenschutz.html#recht-auf-löschung",
    "title": "Datenschutzerklärung",
    "section": "4. Recht auf Löschung",
    "text": "4. Recht auf Löschung\n\na) Löschungspflicht\nSie können von dem Verantwortlichen verlangen, dass die Sie betreffenden personenbezogenen Daten unverzüglich gelöscht werden, und der Verantwortliche ist verpflichtet, diese Daten unverzüglich zu löschen, sofern einer der folgenden Gründe zutrifft:\n\nDie Sie betreffenden personenbezogenen Daten sind für die Zwecke, für die sie erhoben oder auf sonstige Weise verarbeitet wurden, nicht mehr notwendig.\nSie widerrufen Ihre Einwilligung, auf die sich die Verarbeitung gem. Art. 6 Abs. 1 lit. a oder Art. 9 Abs. 2 lit. a DSGVO stützte, und es fehlt an einer anderweitigen Rechtsgrundlage für die Verarbeitung.\nSie legen gem. Art. 21 Abs. 1 DSGVO Widerspruch gegen die Verarbeitung ein und es liegen keine vorrangigen berechtigten Gründe für die Verarbeitung vor, oder Sie legen gem. Art. 21 Abs. 2 DSGVO Widerspruch gegen die Verarbeitung ein.\nDie Sie betreffenden personenbezogenen Daten wurden unrechtmäßig verarbeitet.\nDie Löschung der Sie betreffenden personenbezogenen Daten ist zur Erfüllung einer rechtlichen Verpflichtung nach dem Unionsrecht oder dem Recht der Mitgliedstaaten erforderlich, dem der Verantwortliche unterliegt.\nDie Sie betreffenden personenbezogenen Daten wurden in Bezug auf angebotene Dienste der Informationsgesellschaft gemäß Art. 8 Abs. 1 DSGVO erhoben.\n\n\n\nb) Information an Dritte\nHat der Verantwortliche die Sie betreffenden personenbezogenen Daten öffentlich gemacht und ist er gem. Art. 17 Abs. 1 DSGVO zu deren Löschung verpflichtet, so trifft er unter Berücksichtigung der verfügbaren Technologie und der Implementierungskosten angemessene Maßnahmen, auch technischer Art, um für die Datenverarbeitung Verantwortliche, die die personenbezogenen Daten verarbeiten, darüber zu informieren, dass Sie als betroffene Person von ihnen die Löschung aller Links zu diesen personenbezogenen Daten oder von Kopien oder Replikationen dieser personenbezogenen Daten verlangt haben.\n\n\nc) Ausnahmen\nDas Recht auf Löschung besteht nicht, soweit die Verarbeitung erforderlich ist\n\nzur Ausübung des Rechts auf freie Meinungsäußerung und Information;\nzur Erfüllung einer rechtlichen Verpflichtung, die die Verarbeitung nach dem Recht der Union oder der Mitgliedstaaten, dem der Verantwortliche unterliegt, erfordert, oder zur Wahrnehmung einer Aufgabe, die im öffentlichen Interesse liegt oder in Ausübung öffentlicher Gewalt erfolgt, die dem Verantwortlichen übertragen wurde;\naus Gründen des öffentlichen Interesses im Bereich der öffentlichen Gesundheit gemäß Art. 9 Abs. 2 lit. h und i sowie Art. 9 Abs. 3 DSGVO;\nfür im öffentlichen Interesse liegende Archivzwecke, wissenschaftliche oder historische Forschungszwecke oder für statistische Zwecke gem. Art. 89 Abs. 1 DSGVO, soweit das unter Abschnitt a) genannte Recht voraussichtlich die Verwirklichung der Ziele dieser Verarbeitung unmöglich macht oder ernsthaft beeinträchtigt, oder\nzur Geltendmachung, Ausübung oder Verteidigung von Rechtsansprüchen."
  },
  {
    "objectID": "datenschutz.html#recht-auf-unterrichtung",
    "href": "datenschutz.html#recht-auf-unterrichtung",
    "title": "Datenschutzerklärung",
    "section": "5. Recht auf Unterrichtung",
    "text": "5. Recht auf Unterrichtung\nHaben Sie das Recht auf Berichtigung, Löschung oder Einschränkung der Verarbeitung gegenüber dem Verantwortlichen geltend gemacht, ist dieser verpflichtet, allen Empfängern, denen die Sie betreffenden personenbezogenen Daten offengelegt wurden, diese Berichtigung oder Löschung der Daten oder Einschränkung der Verarbeitung mitzuteilen, es sei denn, dies erweist sich als unmöglich oder ist mit einem unverhältnismäßigen Aufwand verbunden. Ihnen steht gegenüber dem Verantwortlichen das Recht zu, über diese Empfänger unterrichtet zu werden."
  },
  {
    "objectID": "datenschutz.html#recht-auf-datenübertragbarkeit",
    "href": "datenschutz.html#recht-auf-datenübertragbarkeit",
    "title": "Datenschutzerklärung",
    "section": "6. Recht auf Datenübertragbarkeit",
    "text": "6. Recht auf Datenübertragbarkeit\nSie haben das Recht, die Sie betreffenden personenbezogenen Daten, die Sie dem Verantwortlichen bereitgestellt haben, in einem strukturierten, gängigen und maschinenlesbaren Format zu erhalten. Außerdem haben Sie das Recht diese Daten einem anderen Verantwortlichen ohne Behinderung durch den Verantwortlichen, dem die personenbezogenen Daten bereitgestellt wurden, zu übermitteln, sofern\n\ndie Verarbeitung auf einer Einwilligung gem. Art. 6 Abs. 1 lit. a DSGVO oder Art. 9 Abs. 2 lit. a DSGVO oder auf einem Vertrag gem. Art. 6 Abs. 1 lit. b DSGVO beruht und\ndie Verarbeitung mithilfe automatisierter Verfahren erfolgt.\n\nIn Ausübung dieses Rechts haben Sie ferner das Recht, zu erwirken, dass die Sie betreffenden personenbezogenen Daten direkt von einem Verantwortlichen einem anderen Verantwortlichen übermittelt werden, soweit dies technisch machbar ist. Freiheiten und Rechte anderer Personen dürfen hierdurch nicht beeinträchtigt werden."
  },
  {
    "objectID": "datenschutz.html#widerspruchsrecht",
    "href": "datenschutz.html#widerspruchsrecht",
    "title": "Datenschutzerklärung",
    "section": "7. Widerspruchsrecht",
    "text": "7. Widerspruchsrecht\nSie haben das Recht, aus Gründen, die sich aus ihrer besonderen Situation ergeben, jederzeit gegen die Verarbeitung der Sie betreffenden personenbezogenen Daten, die aufgrund von Art. 6 Abs. 1 lit. e oder f DSGVO erfolgt, Widerspruch einzulegen.\nDer Verantwortliche verarbeitet die Sie betreffenden personenbezogenen Daten nicht mehr, es sei denn, er kann zwingende schutzwürdige Gründe für die Verarbeitung nachweisen, die Ihre Interessen, Rechte und Freiheiten überwiegen, oder die Verarbeitung dient der Geltendmachung, Ausübung oder Verteidigung von Rechtsansprüchen.\nSie haben die Möglichkeit, im Zusammenhang mit der Nutzung von Diensten der Informationsgesellschaft - ungeachtet der Richtlinie 2002/58/EG - Ihr Widerspruchsrecht mittels automatisierter Verfahren auszuüben, bei denen technische Spezifikationen verwendet werden.\nSie haben auch das Recht, aus Gründen, die sich aus Ihrer besonderen Situation ergeben, bei der Verarbeitung Sie betreffender personenbezogener Daten, die zu wissenschaftlichen oder historischen Forschungszwecken oder zu statistischen Zwecken gem. Art. 89 Abs. 1 DSGVO erfolgt, dieser zu widersprechen. Ihr Widerspruchsrecht kann insoweit beschränkt werden, als es voraussichtlich die Verwirklichung der Forschungs- oder Statistikzwecke unmöglich macht oder ernsthaft beeinträchtigt und die Beschränkung für die Erfüllung der Forschungs- oder Statistikzwecke notwendig ist."
  },
  {
    "objectID": "datenschutz.html#recht-auf-widerruf-der-datenschutzrechtlichen-einwilligungserklärung",
    "href": "datenschutz.html#recht-auf-widerruf-der-datenschutzrechtlichen-einwilligungserklärung",
    "title": "Datenschutzerklärung",
    "section": "8. Recht auf Widerruf der datenschutzrechtlichen Einwilligungserklärung",
    "text": "8. Recht auf Widerruf der datenschutzrechtlichen Einwilligungserklärung\nSie haben das Recht, Ihre datenschutzrechtliche Einwilligungserklärung jederzeit zu widerrufen. Durch den Widerruf der Einwilligung wird die Rechtmäßigkeit der aufgrund der Einwilligung bis zum Widerruf erfolgten Verarbeitung nicht berührt."
  },
  {
    "objectID": "datenschutz.html#recht-auf-beschwerde-bei-einer-aufsichtsbehörde",
    "href": "datenschutz.html#recht-auf-beschwerde-bei-einer-aufsichtsbehörde",
    "title": "Datenschutzerklärung",
    "section": "10. Recht auf Beschwerde bei einer Aufsichtsbehörde",
    "text": "10. Recht auf Beschwerde bei einer Aufsichtsbehörde\nUnbeschadet eines anderweitigen verwaltungsrechtlichen oder gerichtlichen Rechtsbehelfs steht Ihnen das Recht auf Beschwerde bei einer Aufsichtsbehörde, insbesondere in dem Mitgliedstaat Ihres Aufenthaltsorts, Ihres Arbeitsplatzes oder des Orts des mutmaßlichen Verstoßes, zu, wenn Sie der Ansicht sind, dass die Verarbeitung der Sie betreffenden personenbezogenen Daten gegen die DSGVO verstößt.\nDie Aufsichtsbehörde, bei der die Beschwerde eingereicht wurde, unterrichtet den Beschwerdeführer über den Stand und die Ergebnisse der Beschwerde einschließlich der Möglichkeit eines gerichtlichen Rechtsbehelfs nach Art. 78 DSGVO."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mehrebenenregression mit R",
    "section": "",
    "text": "Dies ist das Skript zur Videoserie Mehrebenenregression mit R, die für die Stelle Quantitatvie Methoden der FernUni Hagen entstanden ist.\nDiese Videoserie besteht aus sechs aufeinander aufbauenden Teilen:\n\nTeil 1: Was ist eine Mehrebenenregression? [Video]\nTeil 2: Wann ist eine Mehrebenenregression angebracht? [ Video]\nTeil 3: Wie werden die Daten für eine Mehrebenregression vorbereitet? [ Video]\nTeil 4: Wie schätzt man eine Mehrebenenregression in R? [Video]\nTeil 5: Wie schätzt man variierende Slopes und Cross-Level Interaktionen? [Video]\nTeil 6: Wie lassen sich die Ergebnisse einer Mehrebenregression berichten? [Video]\n\nZu allen Videos gibt es auf dieser Seite den R Code sowie das Skript.\n\n\nDie Mehrebenenregression ist ein multivariates statistisches Verfahren zur Analyse von Daten, die eine hierarchische Struktur mit mehreren (mindestens zwei) Ebenen aufweisen:\nZum Beispiel:\n\nBefragte in Ländern / Gemeinden / Oragnisationen\nSchüler:innen in Klassen in Schulen\nLänder in Jahren\netc.\n\nImmer wenn die übergeordnete Ebene für ausreichend große Varianz in den Daten sorgt, ist eine einfache Regression ungeeignet. Zum einen werden die Standardfehler unterschätzt. Die Mehrebenenregression schätzt diese korrekt. Außerdem erlaubt es die Mehrebenenregression, die komplexe Datenstruktur elegant zu modellieren und in greifbaren quantities of interest auszudrücken.\nMit der Mehrebenenregression kann man die welche Wechselwirkungen zwischen den unterschidlichen Ebenen besser modellieren und statistisch prüfen, ob diese Unterschiede tatsöächlich bedeutsam sind.\n\n\n\nDamit Sie den Inhalten folgen können, sollten Sie Vorkenntnisse zur linearen OLS Regression haben, sowie Grundlagen in R beherrschen. Ideal wäre es, wenn Sie auch schon einen Lehrbuchtext zur Mehrebenenregression gelesen haben. Eine Auswahl an geeigneten Texten finden Sie am weiter unten auf dieser Seite.\n\n\n\nBA oder MA Studierende aus Wirtschafts- und Sozialwissenschaften, Psychologie oder Digital Humanities, mit Vorkenntnissen in quantitativen Methoden (Grundlagen in R und in multivariater Statistik, z.B. OLS Regression).\n\n\n\n\nTausendpfund, Markus (2020): Mehrebenenanalyse. In: ebd. (Hrsg.): Fortgeschrittene Analyseverfahren in den Sozialwissenschaften. Grundwissen Politik. Springer VS, Wiesbaden. https://doi.org/10.1007/978-3-658-30237-5_5\nPötschke, Manuela. (2020). Mehrebenenmodelle. In: Wagemann, Claudius; Goerres, Achim; Siewert, Markus B. (Hrsg.): Handbuch Methoden der Politikwissenschaft. Springer VS, Wiesbaden. https://doi.org/10.1007/978-3-658-16936-7_29\nGellman, Andrew; Hill, Jennifer (2009): Data-Analysis Using regression and Multilevel/Hierachical Models. Cambridge: Cambridge University Press. Kap. 12 & 13. https://doi.org/10.1017/CBO9780511790942\nFox, John 2016: Applied Regression Analysis and Generalized Linear Models. Sage. Chp 23 Linear Mixed-Effects Models for Hierarchical and Longitudinal Data 700-742."
  },
  {
    "objectID": "mreg1.html#kontext-und-hierarchische-daten",
    "href": "mreg1.html#kontext-und-hierarchische-daten",
    "title": "1. Was ist eine Mehrebenenregression?",
    "section": "Kontext und hierarchische Daten",
    "text": "Kontext und hierarchische Daten\nIn aller Regel laufen solche datengenerierende Prozesse aber kontextabhängig ab. Die Mechanismen die wirken, können je nach Kontext einen stärkeren oder schwächeren Effekt haben, keinen Effekt haben, oder sogar einen umgekehrten Effekt aufweisen.\nDer Kontext, das sind alle möglichen Einbettungen, in denen Menschen sich bewegen: Menschen sind Teil von Gruppen, Klassen, Parteien, Orten, Stadtteilen, Ländern und vielem mehr.\nUnsere datengenerierenden Prozesse führen also zu einer verschachtelten Struktur der Daten (wir nennen das nested data). Man spricht auch von hierarchischen Daten, oder von einer Mehrebenenstruktur.\nSolche Ebenen können neben sozialen Gruppen und Organisationszugehörigkeiten auch räumliche Einheiten sein, oder Erhebungszeitpunkte, oder sogar Experimentalgruppen.\nImmer wenn solche hierarchischen Daten vorliegen, ist die Mehrebenenregression das passende statistische Modell, dass den datengenerierenden Prozess am besten abbilden kann.\nTechnisch spricht man davon, dass es mehrere Ebenen gibt, im englischen Levels. Jede Ebene hat eine bestimmte Anzahl an Fällen (Units).\nWir beschäftigen uns in der Videoserie mit dem einfachen Fall von zwei Ebenen.\n\ndie erste Ebene ist die Individualebene, hier finden wir unsere Befragten. Es ist die unterste Ebene, kurz: L1 für Level 1. Als Index nutzen wir das \\(i\\).\ndie Kontextebene ist die obere Ebene oder L2. Diese Ebene sind die Länder oder allegeminerKlassen bzw. Gruppen. Als Index nutzen wir das \\(j\\).\n\nWir haben \\(n\\) Individuen \\(i_{1, ...n}\\) auf Ebene 1 geclustert in \\(j\\) Klassen/Gruppen \\(j_{1,...m}\\) auf Ebene 2.\nHier ein konkretes Beispiel.\n\n \n\nDie Daten stammen aus dem 9. European Social Survey, - kurz ESS - aus dem Jahr 2018.1\nSie benötigen die ESS Daten um in späteren Videos den R Code aus R-Script-Dateien ausführen zu können. Die Daten können Sie über die Webseite des ESS herunterladen:\nhttps://www.europeansocialsurvey.org/\noder direkt über die DOI-Adresse:\nhttps://doi.org/10.21338/NSD-ESS9-2018\nSchauen wir mal nur auf die Anzahl der Befragten in den 27 teilnehmenden Ländern.\n\n\n\n\n\n\n\n\n\nHier sehen wir bereits die geclusterte Datenstruktur:\nDie Mehrebenenstruktur lässt sich folgendermaßen ausdrücken:\nWir haben \\(47086\\) Individuen \\(i_{1,\\dots47086}\\) auf Ebene 1 geclustert in \\(27\\) Ländern \\(j_{1,\\dots 27}\\) auf Ebene 2.\nDie Ländervariable ist also die Gruppierungsvariable, in denen die Einheiten der unteren Ebene geclustert sind. Theoretisch lassen sich noch weitere Ebenen einfügen. Das würde dann so aussehen…\n\n\n\n\n\n\n\n\n\nHier sind die Befragten in Regionen (z.B. Bundesländern oder Kantonen) geclustert, die dann wiederum Teil von Ländern (also den Nationalstaaten) sind.\nFür die Videoserie bleiben wir aber beim einfachen Beispiel mit zwei Ebenen."
  },
  {
    "objectID": "mreg1.html#varianz-auf-ebene-2",
    "href": "mreg1.html#varianz-auf-ebene-2",
    "title": "1. Was ist eine Mehrebenenregression?",
    "section": "Varianz auf Ebene 2",
    "text": "Varianz auf Ebene 2\n\n\n\n\n\n\nHier kommt ein wichtiger Punkt:\n\n\n\nDass ihre Daten durch das Vorhandensein einer Gruppierungsvariable eine Mehrebenenstruktur aufweist, ist zwar eine notwendige, aber keine hinreichende Bedingung für eine Mehrebenenregression.\n\n\nDenn es ist ja nicht zwingend so, dass diese Struktur auch empirisch zu Unterschieden zwischen den Kontexteinheiten führt.\nOder anders gesagt: es genügt nicht, dass strukturell mehrere Ebenen vorhanden sind. Darüber hinaus muss in der abhängigen Variable auch tatsächlich Variation zwischen den Kontexteinheiten bestehen. Nur dann ist eine Mehrebenenregression sinnvoll.\nMan sagt auch: Es muss ausreichend Varianz auf Ebene 2 vorhanden sein.\nOb das der Fall ist, lässt sich mit Hilfe der sogenannten Intraklassenkorrelation, kurz \\(ICC\\) bestimmen.\nWie man das macht, sehen wir im zweiten Teil der Videoserie.\n\n\n\n\n\n\nAlso…\n\n\n\nWenn ausreichend Varianz auf Ebene 2 vorliegt, können wir die Mehrebenenregression nutzen. Vorteil ist, dass wir bessere Schätzungen für die Regressionsparameter erhalten.\nEin weiterer Vorteil ist, dass wir die Wechselwirkungen zwischen den Ebenen explizit im Modell berücksichtigen können und in wenigen Maßzahlen auch kompakt beschreiben können."
  },
  {
    "objectID": "mreg1.html#grundidee-und-varianten-der-mehrebenenregression",
    "href": "mreg1.html#grundidee-und-varianten-der-mehrebenenregression",
    "title": "1. Was ist eine Mehrebenenregression?",
    "section": "Grundidee und Varianten der Mehrebenenregression",
    "text": "Grundidee und Varianten der Mehrebenenregression\nNun, die Grundidee der Mehrebenenregression ist folgende:\nDas was wir in den Daten an Variation haben, und das ist ja das, was wir erklären wollen, setzt sich (für den Moment verinfacht) aus zwei Quellen zusammen.\nEinmal die Variation die durch Eigenschaften und Merkmale der Individuen entsteht.\nUnd zum anderen die Variation, die aus Eigenschaften des Kontextes entsteht, die auf alle Individuen gleich wirken, die zum gleichen Kontext gehören. Wir haben also zunächst zwei Varianzkomponenten.\nMit Hilfe der Mehrebenenregression lässt sich ein Modell spezifizieren, dass diese Varianzkomponenten korrekt berücksichtigt.\nStarten wir bei einem klassischen OLS Regressionsmodell, hier ein einfaches bivariates Beispiel. Das kennen Sie.\n\nEs gibt ein Intercept und ein Steigungsparameter b.\nAber: Wir berücksichtigen keine Mehrebenenstruktur:\nUnd hier ein einfaches Mehrebenenmodell:\n\n\nWir können den Intercept zwischen den Kontexteinheiten variieren lassen! Wir können also berücksichtigen, dass es unterschiedliche Durchschnittswerte der abhängigen Variable in den verschiedenen Kontexteinheiten gibt. Varying Intercept Model - weil der Intercept variiert.\ndarüber hinaus, können wir auch den Steigungsparameter variieren lassen. Das sehen Sie hier:\n\nWir können also, erlauben, dass der Zusammenhang zwischen abhängiger Variable und unabhängiger Variable in den Ländern unterschiedlich stark sein kann. Das ennt sich dann Varying Intercept, Varying Slope Model.\nUnd wir können tatsächlich auch prüfen, ob und wie stark Merkmale auf der Kontextebene dafür verantwortlich sind, dass diese Unterschiede auftreten. Das wäre dann das Modell mit einer Cross-Level Interaction.\n\nMan könnte es auch so formulieren:\nDer Intercept variiert zwischen den Kontexteinheiten, nimmt also unterschiedliche Werte an. Und diese Varianz können wir versuchen mit den Prädiktoren auf Ebene 2 zu erklären.\nAnalog für die variierenden Steigungsparameter: Auch diese Variation ist erklärungsbedürftig. Und wir können ein Modell erstellen, dass versucht diese Variation auf Kontextebene zu erklären.\n\n\n\n\n\n\nAlso vereinfacht dargestellt:\n\n\n\nDie Mehrebenenregression schätzt ein Modell für die Individualebene, aber im Unterschied zur einfachen OLS dürfen aber bestimmte Parameter zwischen den Kontexteinheiten variieren.\nDie Mehrebenenregression schätzt aber gleichzeitig ein Modell auf Kontextebene, dass es erlaubt, diese Variation auch systematisch erfassen und ggf. zu erklären.\n\n\nJetzt kennen Sie die unterschiedlichen Varianten, wie man Mehrebenenregression spezifizieren kann:\n\nVarying Intercept Modell\n(Varying Slope Modell) Was in der Praxis nur selten ohne varying Intercept gemacht wird\nVarying Intercept, Varying Slope Modell\nVarying Intercept, Varying Slope Modell mit Cross-Level Interaktion\n\nWir können also folgende Fragestellungen beantworten:\n\nWelchen Einfluss haben Prädiktoren auf Ebene 1 an der Varianz auf Ebene 1\nWelchen Einfluss haben Prädiktoren auf Ebene 2 an der Varianz auf Ebene 2\nUnterscheiden sich die Effekte eines Prädiktors der Ebene 1 zwischen Einheiten der Ebene 2\nKönnen Prädiktoren der Ebene 2 erklären, warum sich Effekte von Prädiktoren der Ebene 1 zwischen den Ebene 2 Einheiten unterscheiden?\n\nDiese Modelle schauen wir uns in Teil 4 und 5 der Videoserie noch einmal genauer an und setzen sie mit R um… Zuvor werden wir uns im nächsten Video Nummer zwei anschauen, wann denn eine Mehrebenenregression genutzt werden sollte.\nDamit wären wir am Ende des ersten Videos anfgelangt.\nIm folgenden finden Sie noch eine kleine Aufgabe zur Wiederholung, sowie nochmal eine Übersicht über die Lernziele. Ganz am Ende gibt es noch ein paar Literaturhinweise."
  },
  {
    "objectID": "mreg2.html#umsetzung-in-r",
    "href": "mreg2.html#umsetzung-in-r",
    "title": "2. Wann ist eine Mehrebenenregression angebracht?",
    "section": "Umsetzung in R",
    "text": "Umsetzung in R\nUm den ICC berechnen zu können, schätzen wir ein sogenannten Nullmodell oder leeres Modell (manchmal auch Baseline Modell).\nDabei handelt es sich um ein Mehrebenenmodell, bei dem noch keine unabhängigen Variablen mit ins Modell aufgenommen werden. Es ist ein Random Intercept Modell ohne Prädiktoren.\nDas Nullmodell ist immer der erste Schritt bei einer Mehrebenenanalyse. Es liefert uns die Informationen, wie viel Varianz auf welcher Ebene zu finden ist - und damit, ob es sich überhaupt lohnt, weitere komplexere Mehrebenenmodelle zu schätzen.\nBevor wir dieses Nullmodell berechnen können, müssen wir aber zunächst die Daten einlesen und vorbereiten. Ich nutze das foreign-Paket mit der Funktion read.spss() um den ESS Datensatz den ich heruntergeladen habe einzulesen. Information und Link zum Datensatz finden Sie im ersten Video.\n\n# Einlesen des Datensatzes\nlibrary(foreign)\ness <- read.spss(\"./Daten/ESS9e02.sav\", \n                 use.value.labels = FALSE,\n                 to.data.frame = TRUE,\n                 reencode = TRUE)\n\nAls nächstes erstelle ich einen Mittelwertindex mit der Funktion rowMeans() aus den drei Vertrauens-Items trstpr, trstpl und trstprt. Der Mittelwertindex hat den Vorteil, dass wir nicht so viele Missing Values erhalten wie bei einem additiven Index. Beim additiven Index genügt schon ein NA auf einem der drei Items um zu einem listenweisen Fallausschluss zu führen.\n\n# Operationalisierung der abh. Variable \n# \"Politisches Vertrauen\"\n# Mittelwertindex aus drei Items:\nidx_vars <- c(\"trstprl\",\"trstplt\",\"trstprt\")\ness$pol_vertrauen <- rowMeans(ess[,idx_vars], \n                              na.rm = F)\n#table(ess$pol_vertrauen, useNA = \"always\")\n#DescTools::Desc(ess$pol_vertrauen)\n#table(ess$cntry)\n\nWir haben nun also die Variable pol_vertrauen als abhängige Variable und die Variable cntry als L2 Gruppierungsvariable. Da wir für das Nullmodell noch keine weiteren Prädiktoren benötigen, können wir direkt im nächsten Schritt das Nullmodell schätzen.\nFür die Mehrebenenregression nutzen wir das Paket lme4 von Bates et al. (2015). Darauf aufbauend gibt es noch das Paket lmerTest, welches zusätzlich Signifikanztests mit ausgibt.\n\nlibrary(lme4)\nlibrary(lmerTest) #Eigentlich genügt lmerTest, da das automatisch auch lme4 lädt\n\nBeide Pakete enthalten die Funktion lmer(). lmer steht für linear mixed effects regression.\nDie lmer()-Funktion erwartet im einfachsten Fall nur eine Formel, die das Modell spezifiziert und den Dataframe den wir nutzen.\nWas neu ist, ist dass wir nun explizit angeben müssen, dass ein Intercept geschätzt werden soll.\nDie Formel für den R-Code lautet pol_vertrauen ~ 1 + (1 | cntry).\n\nmreg.0 <- lmer(pol_vertrauen ~ 1 + (1 | cntry),\n               data = ess)\n\nAllgemeiner heißt das:\n\nDie abhängige Variable pol_vertrauen\nwird regrediert ~\nauf einen Ebene 1 Intercept 1\ndabei darf der Intercept 1 variieren | nach der Gruppierungsvariable cntry: also: (1 | cntry)\n\nDass der Intercept mit einer 1 angegeben wird, kommt daher, dass die Regressionsgleichung eigentlich so aussieht:\n\n\\(\\hat{y}_{ij}=\\beta_0j\\) \\(1\\) \\(+\\beta_1x_{ij}\\)\n\nDer Intercept wird nämlich für jeden Befragten mal 1 genommen, was man aber in der Formle nicht ausschreiben muss.\nDas Regressionsobjekt haben wir unter dem Namen mreg.0 gespeichert.\nDas können wir nun aufrufen oder direkt mit der Funktion summary() anzeigen lassen:\n\nsummary(mreg.0)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: pol_vertrauen ~ 1 + (1 | cntry)\n   Data: ess\n\nREML criterion at convergence: 196954.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.7457 -0.7566  0.0255  0.7034  3.8140 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n cntry    (Intercept) 1.053    1.026   \n Residual             4.471    2.115   \nNumber of obs: 45391, groups:  cntry, 27\n\nFixed effects:\n            Estimate Std. Error      df t value Pr(>|t|)    \n(Intercept)   3.8413     0.1978 25.9987   19.42   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nViele Informationen in diesem Output sind an dieser Stelle nicht wichtig. Für uns sind folgende Quanitites of Interest relevant:\nUnten bei den Fixed Effects in blau hervorgehoben, sehen wir den durchschnittlichen Wert der variienden Intercepts, also den Grand Mean \\(\\gamma_{00}\\). Dieser liegt bei \\(3.8\\).\nAber: der Intercept darf ja variierenden! Und wie groß diese Varianz ist, sehen wir oben bei den Random Effects, hier in rot hervorgehoben. Hier finden wir die Varianzkomponenten des Modells. Also: das was variieren darf, und was noch nicht systematisch im Modell erklärt wird. Daher auch die Bezeichnung Random Effects.\nAuf der Ebene der Gruppierungsvariable cntry haben wir einen variierenden Intercept, das ist das \\(\\beta_{0j}\\), mit einer Varianz von \\(1.05.\\)\nÜbrig bleibt eine Resiudalvarianz auf Ebene 1, also das was nicht durch den variierenden Intercept erklärt wird. Das sind hier \\(4.47.\\)\nMit diesen beiden Zahlen lässt sich nun der \\(ICC\\) berechnen.\n\\(\\frac{1.05}{1.05 + 4.47}= 0.19\\)\nUm das nicht von Hand erledigen zu müssen, gibt es im Paket performance die Funktion icc(), die man auf das Nullmodell anwendet:\n\nlibrary(performance)\nicc(mreg.0)\n\n# Intraclass Correlation Coefficient\n\n    Adjusted ICC: 0.191\n  Unadjusted ICC: 0.191\n\n\nWir sehen also der\\(ICC\\) beträgt 0.19065 - 19.1 Prozent der Varianz liegen auf Ebene 2.\nDas ist ziemlich guter Wert für eine abhängige Variable aus dem Bereich der politikwissenschaftlichen Einstellungs- und Verhaltensforschung. Der datengenerierende Prozess resultiert also tatsächlich in einer geclusterten bzw. hierarchischen Datenstruktur. Die obere Ebene ist für fast ein Fünftel der Varianz in den Daten verantwortlich.\nSomit wissen wir: Eine Mehrebenenregression ist unbedingt einer einfachen OLS Regression vorzuziehen, wenn wir korrekte Ergebnisse erhalten wollen, denen wir auch trauen können.\nTun wir das nicht, korrelieren die Fehler der Individualebene mit einem Kontextmerkmal, nämlich der Länderzugehörigkeit der Befragten. Wir nehmen an, die Befragten wären unabhängig voneinander, was sie in Wahrheit nicht sind.\nUnter anderem werden die Standardfehler der Regressionskoeffizienten im einfachen OLS Modell auf Basis der gesamten Stichprobe berechnet. Es wird nicht berücksichtigt, dass die Varianzen und Fallzahlen in den Gruppen unterschiedlich sind. Als Folge werden die Standardfehler unterschätzt.\nWenn die Standardfehler aber kleiner sind, als sie sein müssten, wird auch die Irrtumswahrscheinlichkeit beim Signifikanztest unterschätzt.\nIm schlechtesten Fall gehen Sie also von signifikanten Effekten aus, wo in Wahrheit kein Zusammenhang zu finden ist.\nSie sehen, wenn die Daten eine Mehrebenenstruktur aufweisen, sollten Sie auch unbedingt ein Mehrebenenmodell schätzen!\nIm nächsten Teil 3 werden wir uns aber zunächst mit der Operationalisierung, also der Vorbereitung der Daten für die Mehrebenenregression beschäftigen."
  },
  {
    "objectID": "mreg3.html#bildung",
    "href": "mreg3.html#bildung",
    "title": "3. Wie werden die Daten für eine Mehrebenregression vorbereitet?",
    "section": "Bildung",
    "text": "Bildung\nAls erstes operationalisiere ich unsere Haupterklärungsvariable Bildung.\nDie Messung erfolgt über die “International Standard Classification of Education” - eisced, welche die nationalen Bildungabschlüsse in eine vergleichbare Skala überführt.\nDie numerischen Merkmalsausprägungen reichen von \\(1\\) less than lower secondary bis \\(7\\) higher tertiary education.\nStreng genommen handelt es sich um eine ordinale Skala, aus didaktischen Gründen nutze ich sie für dieses Beispiel als metrische Skala.\n\n# Operationalisierung der unabh. Variable \n# Bildung\ness$bildung <- ess$eisced \n\n# NAs definieren:\n# `0` (nicht harmonisierbar) und `55` (andere) auf `NA` setzten\ness$bildung[ess$bildung %in% c(0,55)] <- NA\n\n#Desc(ess$bildung)\n\nNeben der abhängigen und der uns interessierenden unabhängigen Variable, müssen wir noch weitere Variablen im Modell berücksichtigen - die sogenannten Kontrollvariablen.\nFür unser Beispielfragestellung nutze ich die Variablen:\n\nWahrgenommene politische Responsivität\nZufriedenheit mit der Wirtschaftslage\nSoziales Vertrauen"
  },
  {
    "objectID": "mreg3.html#wahrgenommene-politische-responsivität",
    "href": "mreg3.html#wahrgenommene-politische-responsivität",
    "title": "3. Wie werden die Daten für eine Mehrebenregression vorbereitet?",
    "section": "Wahrgenommene politische Responsivität",
    "text": "Wahrgenommene politische Responsivität\nMittelwertindex aus zwei Items\nHow much would you say the political system in [country] allows people like you to have a say in what the government does?\nAnd how much would you say that the political system in [country] allows people like you to have an influence on politics?\nDie Antwortskala umfasst eine 5er Skala:\n\n\\(1\\) Not at all\n\\(5\\) A great deal\n\n\n# Operationalisierung der unabh. Variable \n# Wahrgenommene politische Responsivität \n# Mittelwertindex aus zwei Items \n\nidx_vars <- c(\"psppsgva\",\"psppipla\")\ness$responsivitaet <- rowMeans(ess[,idx_vars], \n                               na.rm = F)\n\n#Desc(ess$responsivitaet)"
  },
  {
    "objectID": "mreg3.html#zufriedenheit-wirtschaftslage",
    "href": "mreg3.html#zufriedenheit-wirtschaftslage",
    "title": "3. Wie werden die Daten für eine Mehrebenregression vorbereitet?",
    "section": "Zufriedenheit Wirtschaftslage",
    "text": "Zufriedenheit Wirtschaftslage\nOn the whole how satisfied are you with the present state of the economy in [country]?\n\n\\(0\\) Extremely dissatisfied\n\\(10\\) Extremely satisfied\n\n\n# Operationalisierung der unabh. Variable \n# \"Zufriedenheit Wirtschaftslage\"\n\ness$zufr_wirtschaft <- ess$stfeco\n#Desc(ess$zufr_wirtschaft)"
  },
  {
    "objectID": "mreg3.html#soziales-vertrauen",
    "href": "mreg3.html#soziales-vertrauen",
    "title": "3. Wie werden die Daten für eine Mehrebenregression vorbereitet?",
    "section": "Soziales Vertrauen",
    "text": "Soziales Vertrauen\nSoziales Vertrauen messen wir mit Hilfe der Social Trust Scale. Informationen zu dieser Skala finden Sie beim GESIS in der Zusammenstellung sozialwissenschaftlicher Items und Skalen (ZIS) (Breyer 2015).\nDer Index wurde ursprünglich von Rosenberg (1956) vorgeschlagen. Er besteht aus den drei Items:\n\nVertrauenswürdigkeit ppltrst\nFairness pplfair\n\nHilfsbereitschaft pplhlp\n\nGenerally speaking, would you say that most people can be trusted, or that you can’t be too careful in dealing with people?\nAuch hier liegt für jedes Item eine 10er Skala vor, z.B. für Vertrauen lauten die ANtwortkategorien:\n\n\\(0\\) You can’t be too careful\n\\(10\\) Most people can be trusted\n\nHohe Werte bedeuten positive Einstellungen.\n\n# Operationalisierung der unabh. Variable \n# Soziales Vertrauen\n\nidx_vars <- c(\"ppltrst\", \"pplfair\", \"pplhlp\")\n\ness$soz_vertrauen <- rowMeans(ess[,idx_vars], \n                               na.rm = F)\n#Desc(ess$soz_vertrauen)"
  },
  {
    "objectID": "mreg3.html#kontextdaten",
    "href": "mreg3.html#kontextdaten",
    "title": "3. Wie werden die Daten für eine Mehrebenregression vorbereitet?",
    "section": "Kontextdaten",
    "text": "Kontextdaten\nWenn man eine Mehrebenenregression rechnet, möchte man häufig auch Variablen der Makroebene nutzen. Wenn die Gruppierungsvariable Länder oder andere administrative Einheiten sind, gibt es diese Daten häufig bei den statistischen Ämtern. Zum Beispiel Eurostat, dem Statistischen Bundesamt, der Weltbank, der OECD oder den Vereinten Nationen.\nAber: wir sind in einer sehr komfortablen Situation, denn im Rahmen des ESS Programms wurden auch Makro-Datensätze erstellt, in denen Daten aus verschiedenen Quellen zusammengetragen wurden. Diese Datensätze enthalten neben den Individualdaten auch Kontextdaten.\nAuch der Makrodatensatz ist nach Registrierung kostenlos verfügbar. Jedoch ist der Makrodatensatz etwa 2 GB groß.\nStatt des ganzen Datensatzes, habe ich ihnen einen kleinen Ausschnitt davon als csv-Datei vorbereitet.\nDie csv-Datei finden Sie als Download bei den Ressourcen. Lesen wir zuerst den vorbereiteten Makrodatensatz ein:\n\n# Einlesen Makrodaten einlesen und mit merge() hinzuspielen\n# ggf. Daetipfad anpassen\ness_macro <- read.table(\"./Daten/ess2018_macro.csv\",\n                        sep=\";\", header=T)\nhead(ess_macro)\n\n  cntry c_tensys_2018 c_ticpi_2018 c_gini_2018\n1    AT            64           76        26.8\n2    BE            88           75        25.7\n3    BG            28           42        39.6\n4    CH            88           85        29.7\n5    CY            30           59        29.1\n6    CZ            28           59        24.0\n\n#View(ess_macro)\n\nDiese Datei enthält neben der Gruppierungsvariable cntry drei weitere Variablen:\n\nc_ticpi_2018 Corruption Perceptions Index1\nc_gini_2018 GINI Index2\nc_tensys_2018 System Tenure3\n\nMit diesem Datensatz haben wir gleich auch die Gelegenheit einen typischen Schritt der Datenvorbereitung umzusetzen: das mergen von Datensätzen.\nMegren heißt, dass man zwei Datensätze anhand einer Schlüsselvariable zusammenspielt.\nProbieren wir es aus:\nWir sehen im Environment Fenster in R, dass der Datensatz 4 Variablen mit 29 Beobachtungen enthält. Die head()-Funktion gibt uns einen ersten Blick auf die Daten. Wir sehen, dass jede Beobachtung, also jeder Fall ein Land ist.\nDer ESS-Datensatz den wir vorhin eingelesen hatten, hat als Beobachtungseinheit Individuen.\nTrotzdem können wir beide Datensätze zusammenspielen. Dafür nutzen wir die cntry-Variable als Schlüsselvariable. Jeder Befragte eines Landes, bekommt den jeweiligen Wert des Landes aus dem Makrodatensatz zugespielt.\nDafür nutzen wir die merge()-Funktion:\n\ness_micro <- ess\ness <- merge(ess_micro, ess_macro, # Die beiden Datensätze die zusammengespielt werden\n             by = \"cntry\", # Die Schlüsselvariable\n             all.x = T) # Das alle Fälle des x-Datensatzes (des erstgenannten) behalten werden\n\nDer neue ESS Datensatz enthält wie der Mikro-Datensatz die gut 47.000 Befragten, aber drei zusätzliche Variablen aus dem Makrodatensatz. Die vierte Variable aus dem Makrodatensatz muss ja nicht übernommen werden, denn die cntry Variable war ja auch vorher schon ein Merkmal im Mikro-Datensatz.\nVon den drei Kontextvariablen nutzen wir in unserem Beispiel nur die Korruptionsvariable. Die anderen beiden können Sie für selbstständiges Üben nutzen."
  },
  {
    "objectID": "mreg3.html#missing-values-ausschließen",
    "href": "mreg3.html#missing-values-ausschließen",
    "title": "3. Wie werden die Daten für eine Mehrebenregression vorbereitet?",
    "section": "Missing Values ausschließen",
    "text": "Missing Values ausschließen\nUm einen Datensatz zu erhalten, der in über alle Modelle die gleiche Fallzahl aufweist, werden diejenigen Fälle ausgeschlossen, die auf mindestens einer der für die Analysen genutzten vVariablen fehlende Werte aufweisen (“Listenweiser Fallausschluss”).\n\n# Missing Values ausschließen\nvariablen_im_modell <- c(\"pol_vertrauen\",\n                         \"bildung\",      \n                         \"responsivitaet\",                         \n                         \"zufr_wirtschaft\",\n                         \"soz_vertrauen\", \n                         \"cntry\",\n                         \"c_ticpi_2018\")\ness <- na.omit(ess[,variablen_im_modell])\n\nEin Hinweis: Da bei den Makrovariablen Daten für zwei Länder fehlen, liegen nach diesem Ausschluss fehlender Werte nur Daten für gut 40.000 Befragte aus 25 Ländern vor."
  },
  {
    "objectID": "mreg3.html#zentrieren",
    "href": "mreg3.html#zentrieren",
    "title": "3. Wie werden die Daten für eine Mehrebenregression vorbereitet?",
    "section": "Zentrieren",
    "text": "Zentrieren\nKommen wir zu einem weiteren wichtigen Schritt der Datenvorbereitung.\nIn Mehrebenenmodellen ist es häufig üblich, dass die unabhängigen Variablen auf Ebene 1 mittelwertzentriert werden. Das sogenannte Grand-Mean-Centering sorgt dafür, dass der jeweilige Intercept eines Landes \\(\\beta_{0j}\\) als Abweichung vom Grand Mean interpretiert werden kann.\nEine andere Möglichkeit ist es, die Variablen auf einen vergleichbaren Wertebereich, zum Beispiel zwischen 0 und 1 zu standardisieren.\nWie man sich auch entscheidet, wichtig ist, dass man an folgendes denkt: der Intercept einer Regression ist der Vorhersagewert an der Stelle der Regressionsgeraden, bei der alle unabhängigen Variablen den Wert 0 annehmen.\nOder anders: Der Wert der Regressionsgeraden für \\(X=0\\), wo die Regressionsgerade die Y-Achse schneidet.\nWenn Ihre unabhängigen Variablen den Wertebereich \\(0\\) gar nicht enthält, kann man auch den Intercept inhaltlich nicht interpretieren.\nIn unserem Beispiel entscheide ich mich für das Mittelwertzentrieren. Wir haben nur metrische Variablen im Beispiel daher nutze die scale()-Funktion. Diese Funktion dient eigentlich zur z-Transformation: sie nimmt eine Variable, zieht den Mittelwert ab und teilt durch die Standardabweichung. Allerdings möchte ich nicht, dass durch die Standardabweichung geteilt wird, das teile ich der Funktion mittels scale=FALSE mit.\nDiese Funktion kann ich direkt auf die relevanten Spalten des Datensatzes anwenden. Um herauszufinden welche das sind, schaue ich mir die names() an.\nUnsere unabhängigen Variablen befinden sich in Spalte 2 bis 5 des Datensatzes. Jetzt kann ich mit der Indizierungsklammer die Spalten auswählen und mit scale() zentrieren.\nDas speichere ich in einem neuen Objekt und überschreibe danach die ursprünglichen Variablen 2 bis 5.\n\n# Zentrieren der Ebene 1 x-Variablen\n# Diese sind an 2. bis 5. und 7. Stelle im Datensatz\n\n#names(ess)\n#ess[,c(2:5)]\n#scale(ess[,c(2:5)], scale=F)\ness_centered <- as.data.frame(scale(ess[,c(2:5)], scale=F))\ness[,c(2:5)] <- ess_centered"
  },
  {
    "objectID": "mreg4.html",
    "href": "mreg4.html",
    "title": "4. Wie schätzt man eine Mehrebenenregression in R?",
    "section": "",
    "text": "Themenüberblick\nIm vorigen Teil 2 haben wir gesehen, wie man mit Hilfe des sogenannten Nullmodells berechnet, ob eine Mehrebenenregression überhaupt notwendig ist. Und in Teil 3, wie man die Daten für die Mehrebenenregression vorbereitet.\nIn diesem vierten Teil geht es nun darum: Wie schätzt man eine Mehrebenenregression in R? Und natürlich: wie interpretiert man die Ergebnisse?\nDas Video finden Sie hier.\nDazu schätzen wir zwei grundlegende Modelle:1\n\nEin Modell mit variierenden Intercepts mit Prädiktoren auf L1\nEin Modell mit variierenden Intercepts mit Prädiktoren auf L1 und L2\n\nLernziele für dieses Video sind…\n\ndass Sie ein einfaches Mehrebenenmodell als Formel ausdrücken können\ndass Sie wissen, wie man das einfache Mehrebenenmodell in R umsetzt\ndass Sie die relevanten Quantities of Interest kennen und interpretieren können.\n\nDas alles schauen wir uns direkt in R an…\n\n\nVariierende Intercepts mit Prädiktoren auf L1\nBevor wir mit dem ersten Modell loslegen, führen Sie bitte das komplette RScript zu Video 3 aus (RScript_mreg3.R bei den Ressourcen). Mit der source()-Funktion können Sie das direkt aus dem neuen Script heraus aufrufen, ohne die Datei öffnen zu müssen.\n\nsource(\"./Ressourcen/RScript_mreg3.R\") #Pfad zur Datei ggf. anpassen\n\nWir sehen zwar keinen Output, aber den benötigen wir auch nicht. Wir wollen nur die Objekte im Environment haben, insbesondere, den fertig vorbereiteten ESS Datensatz.\nKommen wir nun zum ersten Modell. Das erste Mehrebenenmodell ist ein Varying Intercept Modell mit Prädiktoren auf Ebene 1:\nDie Form ist dieselbe wie beim Nullmodell. Allerdings enthält die Formel nun auch die Ebene 1 Prädiktoren \\(x_1\\) bis \\(x_4\\).\n\n\n\\(y_{ij} = \\beta_{0j} +\\) \\(\\beta_{1}x_{1ij} + \\beta_{2}x_{2ij} + \\beta_{3}x_{3ij} + \\beta_{4}x_{4ij}\\) \\(+ r_{ij}\\)\n\nmit\n\n\\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\)\n\n\nStatt \\(x_1\\) bis \\(x_4\\) könnten wir auch die entsprechenden Variablen aufführen: bildung, responsivitaet, zufr_wirtschaft und soz_vertrauen.\nDiese setzen wir auch in der Formel in der lmer()-Funktion ein:\n\nlibrary(lmerTest) \nmreg1 <- lmer(pol_vertrauen ~ 1 + bildung + \n                responsivitaet + zufr_wirtschaft + soz_vertrauen + \n                (1 | cntry),  \n              data=ess)\n\nMit summary() können wir die Ergebnisse anzeigen lassen:\n\nsummary(mreg1)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: pol_vertrauen ~ 1 + bildung + responsivitaet + zufr_wirtschaft +  \n    soz_vertrauen + (1 | cntry)\n   Data: ess\n\nREML criterion at convergence: 154604\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-4.167 -0.657  0.012  0.647  5.390 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n cntry    (Intercept) 0.147    0.384   \n Residual             2.784    1.669   \nNumber of obs: 39998, groups:  cntry, 25\n\nFixed effects:\n                   Estimate  Std. Error          df t value\n(Intercept)         3.92905     0.07725    23.96503   50.86\nbildung            -0.02501     0.00486 39991.56791   -5.15\nresponsivitaet      0.84569     0.01141 39988.92072   74.09\nzufr_wirtschaft     0.31301     0.00439 39651.68675   71.33\nsoz_vertrauen       0.21042     0.00499 39958.23593   42.15\n                            Pr(>|t|)    \n(Intercept)     < 0.0000000000000002 ***\nbildung                   0.00000027 ***\nresponsivitaet  < 0.0000000000000002 ***\nzufr_wirtschaft < 0.0000000000000002 ***\nsoz_vertrauen   < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) bildng rspnsv zfr_wr\nbildung     -0.002                     \nresponsivtt -0.001 -0.177              \nzfr_wrtschf  0.003 -0.011 -0.242       \nsoz_vertran  0.003 -0.104 -0.140 -0.231\n\n\nSchauen wir als erstes auf die Fixed Effects.\nWir sehen, dass es neben dem Intercept \\(\\beta_{0j}\\) nun auch weitere Koeffizienten gibt. Das sind die b-Koeffizienten für die unabhängigen Variablen, also \\(\\beta_1\\) bis \\(\\beta_4\\).\nWie bereits beim Nullmodell ist der Intercept der Mittelwert der variierenden Intercepts $beta_{0j} - also das, was in der Regressionsgleichung mit \\(\\gamma_{00}\\) bezeichnet wurde.\nDie anderen Regressionsparameter sind nicht variierende Regressionsparameter, und sind wie ganz normale Regressionskoeffizienten zu interpretieren:\nAlle Variablen haben einen signifikanten Einfluss, wie wir an der letzten Spalte sehen.\nMit Zunahme von Bildung um einen Skalenpunkt, sinkt das politische Vertrauen um \\(-0.025\\).\nEine vorläufige Antwort auf unsere Forschungsfrage lautet also: Bildung beeinflusst das politische Vertrauen negativ.\nDie anderen Determinanten haben einen positiven Effekt auf politisches Vertrauen. Da die wahrgenommene politische Responsivität eine andere Skalenbreite aufweist, können wir die Effektstärken jedoch nicht direkt miteinander vergleichen.\nSchauen wir uns nun die Random Effects an.\nDie Random Effects berichten die Varianz der Residuen der beiden Gleichungen:\n\n\n\\(y_{ij} = \\beta_{0j} + \\beta_{1}x_{1ij} + \\beta_{2}x_{2ij} + \\beta_{3}x_{3ij} + \\beta_{4}x_{4ij} + r_{ij}\\)\n\nmit\n\n\\(\\beta_{0j} = \\gamma_{00} + u_{0j}\\)\n\n\nAlso: Wie groß ist die unerklärte Varianz auf Individualebene \\(r_{ij}\\) - das finden wir in der Tabelle hier unter “Residual”. Der Wert ist \\(2.784\\).\nUnd wie groß ist die Varianz der variierenden Intercepts \\(u_{0j}\\). Also: Wie sehr streuen die Ländermittelwerte \\(\\beta_{0j}\\) um den Grand Mean \\(\\gamma_{00}\\)? Das sehen wir bei “cntry (Intercept)”. Dieser Wert ist \\(0.147\\).\nWir können uns auch anschauen, wie diese Streuung um den Grand Mean ganz konkret aussieht. Dafür gibt es die Funktion ranef() - sie steht für random Effects und berichtet die Werte jedes einzelnen \\(\\beta_{0j}\\) - also den jeweiligen länderspezifischen Intercept:\n\nranef(mreg1)\n\n$cntry\n   (Intercept)\nAT     -0.0536\nBE      0.3936\nBG     -0.2900\nCH      0.2334\nCY     -0.0587\nCZ     -0.3795\nDE     -0.3467\nEE      0.1977\nES     -0.3705\nFI      0.4898\nFR      0.2963\nGB     -0.1435\nHR     -0.5364\nHU      0.6308\nIE     -0.0381\nIT      0.3565\nLT     -0.3225\nLV     -0.3304\nNL      0.6036\nNO      0.3598\nPL     -0.4996\nPT     -0.2344\nSE      0.4528\nSI     -0.5826\nSK      0.1719\n\nwith conditional variances for \"cntry\" \n\n\nDa wir zuvor alle unabhängigen Variablen an deren Grand Mean zentriert haben, sind diese länderspezifischen Intercepts als Abweichung vom Grand Mean zu interpretieren.\nFür Belgien BE liegt der länderspezifische Intercept \\(\\beta_{0~Belgien}\\) also \\(0.394\\) Skalenpunkte über dem fixierten Intercept bzw. Grand Mean \\(\\gamma_{00}\\) von \\(3.93\\).\nFür Deutschland DE liegt er \\(-0.347\\) Skalenpunkte unter diesem Wert.\nAnalog kann man sich auch die fixierten Effekte ausgeben lassen.\n\nfixef(mreg1)\n\n    (Intercept)         bildung  responsivitaet zufr_wirtschaft   soz_vertrauen \n          3.929          -0.025           0.846           0.313           0.210 \n\n\nWas uns nun noch interessiert ist, wie gut unser Modell die abhängige Variable erklärt.\nBeim OLS-Regressionsmodell betrachten wir dafür den Determinantionskoeffizienten \\(R^2\\) als Maß für Varianzaufklärung. Auch beim Mehrebenenmodell können wir prüfen, wie viel Varianz durch das Modell erklärt wird.\nIm einfachsten Fall können wir berechnen, wieviel der Varianz die in den Random Effects des Nullmodells steckt, durch ein Modell mit Prädiktoren erklärt wird.\nBerechnen wir also noch Mal auf das Nullmodell auf Basis der jetzt 25 Länder:\n\nmreg0 <- lmer(pol_vertrauen ~ 1 + (1 | cntry),  \n              data=ess)\nsummary(mreg0)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: pol_vertrauen ~ 1 + (1 | cntry)\n   Data: ess\n\nREML criterion at convergence: 171592\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-2.811 -0.741  0.038  0.694  3.916 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n cntry    (Intercept) 1.11     1.05    \n Residual             4.26     2.06    \nNumber of obs: 39998, groups:  cntry, 25\n\nFixed effects:\n            Estimate Std. Error     df t value           Pr(>|t|)    \n(Intercept)    3.892      0.211 23.996    18.4 0.0000000000000011 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nas.data.frame(VarCorr(mreg0))[,4]\n\n[1] 1.11 4.26\n\n\nAuf Ebene 2, der Ebene der Länder haben wir eine Varianz von \\(1.112\\). Auf Individualebene eine Varianz von \\(4.256\\).\n\nsummary(mreg1)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: pol_vertrauen ~ 1 + bildung + responsivitaet + zufr_wirtschaft +  \n    soz_vertrauen + (1 | cntry)\n   Data: ess\n\nREML criterion at convergence: 154604\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-4.167 -0.657  0.012  0.647  5.390 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n cntry    (Intercept) 0.147    0.384   \n Residual             2.784    1.669   \nNumber of obs: 39998, groups:  cntry, 25\n\nFixed effects:\n                   Estimate  Std. Error          df t value\n(Intercept)         3.92905     0.07725    23.96503   50.86\nbildung            -0.02501     0.00486 39991.56791   -5.15\nresponsivitaet      0.84569     0.01141 39988.92072   74.09\nzufr_wirtschaft     0.31301     0.00439 39651.68675   71.33\nsoz_vertrauen       0.21042     0.00499 39958.23593   42.15\n                            Pr(>|t|)    \n(Intercept)     < 0.0000000000000002 ***\nbildung                   0.00000027 ***\nresponsivitaet  < 0.0000000000000002 ***\nzufr_wirtschaft < 0.0000000000000002 ***\nsoz_vertrauen   < 0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) bildng rspnsv zfr_wr\nbildung     -0.002                     \nresponsivtt -0.001 -0.177              \nzfr_wrtschf  0.003 -0.011 -0.242       \nsoz_vertran  0.003 -0.104 -0.140 -0.231\n\n\nIn unserem Modell mreg1 ist die Varianz der Intercepts nur noch bei \\(0.147\\) und die Residualvarianz auf Individualebene bei \\(2.784\\)\nAlso auf Ebene 1 bleiben nur noch \\(\\frac{2.784}{4.256}=0.654\\), also 65.4 Prozent der Varianz übrig.\nOder anders ausgedrückt: Wir erklären 34.6 Prozent der Varianz auf Ebene 1.\nDas können wir auch allgemeiner ausdrücken:\n\\(R^2_{L1}=1-\\frac{s^2_{L1_{Modell}}}{s^2_{L1_{Nullmodell}}}\\)\nUnd wir können auch für Ebene 2 berechnen, wieviel der im Nullmodell auf Ebene 2 vorhandenen Varianz durch unser Modell mit Prädiktoren erklärt wurde.\n\\(R^2_{L2}=1-\\frac{s^2_{L2_{Modell}}}{s^2_{L2_{Nullmodell}}}\\)\nDas sind \\(1-\\frac{0.147}{1.112}=0.868\\)- also 86.8 Prozent der Varianz auf Ebene 2 werden durch unser Modell mreg1 bereits erklärt.\n“Moment!” werden Sie jetzt sagen! Wie soll das denn gehen! Wir haben doch nur Prädiktoren der Individualebene im Modell! Wie können individuelle Merkmale von Befragten Varianz zwischen den Ländern erklären?\nRichtig! Das ist eine gute Frage. Drücken Sie Pause und nehmen Sie sich ein paar Minuten um zu überlegen, was der Grund sein könnte.\nGut, hier kommt die Auflösung: Es handelt sich um sogenannte Kompositionseffekte.\nNehmen wir Beispielsweise unsere unabhängige Variable Zufriedenheit mit der Wirtschaftslage. Das ist eine Variable der Individualebene und die Befragten in den Ländern können unterschiedliche Werte auf dieser Variable einnehmen. Es ist kein Kontextmerkmal, dass für alle Befragten eines Landes gleich ist.\nAber: Wenn viele oder im Extremfall alle Individuen eines Landes besonders hohe Werte auf dieser Variable einnehmen , dagegen in einem anderen Land viele Individuen eine sehr geringe Zufriedenheit mit der Wirtschaft aufweisen, dann wird - wenn diese Variable auch einen Einfluss auf das politische Vertrauen hat - allein durch die Zusammensetzung der Gruppen das durchschnittliche Niveau der abhängigen Variable in den Ländern beeinflusst.\nAlso dadurch, dass sich die Länder hinsichtlich der Zusammensetzung der Individuen und ihrer Merkmale unterscheiden, wird bereits Varianz zwischen den Ländern erklärt. Denn mit durchschnittlich höherer Zufriedenheit mit der Wirtschaft geht ja auch durchschnittlich höheres politisches Vertrauen einher.\nSomit kann also die Zusammensetzung der Individuen hinsichtlich ihrer Merkmale auf Ebene 1 als Kompositionseffekt Varianz auf Ebene 2, also zwischen den Ländern erklären.\nSo simpel und klar die Berechnung und Interpretation dieser \\(R^2\\) Maße für die beiden Ebenen auch ist: Wenn die Modelle komplexer werden und später mehr als nur ein random Effect (also mehr als nur ein variierender Intercept) vorliegt, dann kann man diese ebenenspezifischen \\(R^2\\) nicht mehr nutzen.\nNakagawa/Schielzeth 2012 haben noch weitere Nachteile angeführt und schlagen eine Alternative Berechnung für ein \\(R^2\\) für Mehrebenenregressionen vor.\nWir können \\(Nakagawa~R^2\\) mit Hilfe des performance-Paketes und der Funktion r2() berechnen:\n\nlibrary(performance)\nr2(mreg1)\n\n# R2 for Mixed Models\n\n  Conditional R2: 0.448\n     Marginal R2: 0.419\n\n\nDas marginale \\(R^2\\) können wir dabei ignorieren, da es die Varianzen der Random Effects nicht berücksichtigt. Stattdessen betrachten wir das konditionale \\(R^2\\).\nUnser Modell erklärt also etwa 44.8 Prozent der Varianz in den Daten.\nDarüber hinaus bietet das performance-Paket die Möglichkeit mit der Funktion model_performance() bei Bedarf weitere Goodness of Fit Maße zu berechnen:\n\nmodel_performance(mreg0)\n\n# Indices of model performance\n\nAIC       |      AICc |       BIC | R2 (cond.) | R2 (marg.) |   ICC |  RMSE | Sigma\n-----------------------------------------------------------------------------------\n1.716e+05 | 1.716e+05 | 1.716e+05 |      0.207 |      0.000 | 0.207 | 2.062 | 2.063\n\n\nKommen wir nun zum nächsten Schritt.\n\n\nVariierende Intercepts mit Prädiktoren auf L1 und L2\nWir ergänzen das Modell nun um unseren Prädiktor auf Ebene 2.\nAls zweite Forschungsfrage wollen wir wissen, ob das Ausmaß an Korruption in einem Land den Effekt von Bildung beeinflussen kann.\nWir nehmen also den Corruption Perception Index (CPI) von Transparency International mit ins Model. Der CPI ist eine Skala von 0 ‘sehr korrupt’ bis 100 ‘sehr sauber’.\nNochmal zur Erinnerung, es ist ein Expertenrating, daher wird der Index Corruption Perception Index genannt. 100 steht nicht für keine objektive Korruption, sondern Transparency International nennt es dann ‘sehr sauber’.\nDamit wir die Effekte später intuitiver Interpretieren können, drehen wir die Variable CPI, famit höhere Werte, höhere Korruption bedeuten.\nDie original Variable heißt c_ticpi_2018. Diese wird gedreht, dann schauen wir uns die Verteilung mit einer Grafik an.\n\ness$korruption <- abs(ess$c_ticpi_2018-100)\nlibrary(ggplot2)\nggplot(ess, aes(x=cntry, y=korruption)) +\n  geom_bar(stat = \"summary\", fun = \"mean\") +\n  scale_y_continuous(limits=c(0,100)) +\n  theme(axis.text=element_text(size=6))\n\n\n\n\n\n\n\n\nDa die Variable auf Ebene 2 liegt, kann sie nur den länderspezifischen Mittelwert der abhängigen Variable beeinflussen.\nDie länderspezifische Korruption muss also Teil der Gleichung des variierenden Intercepts \\(\\beta_{0j}\\) sein. Wir ergänzen dafür die Koeffizienten \\(\\gamma_{01j}\\) in der zweiten Zeile der Gleichung:\n\n\n\\(y_{ij} = \\beta_{0j} + \\beta_{1}x_{1ij} + \\beta_{2}x_{2ij} + \\beta_{3}x_{3ij} + \\beta_{4}x_{4ij} + r_{ij}\\)\n\nmit\n\n\\(\\beta_{0j} = \\gamma_{00} +\\) \\(\\gamma_{01j}\\) \\(+ u_{0j}\\)\n\n\n\\(\\gamma_{01j}\\) ist also Regressionskoeffizient für den Einfluss der Variable korruption auf den variierenden Intercept.\nDurch die Aufnahme dieser unabhängigen Variable auf Ebene 2 sollte zuvor unerklärte Varianz auf Ebene 2 geringer werden - also das Ebene 2 Residuum \\(u_{0j}\\) geringer werden.\nOb das so ist, sehen wir gleich.\nIm R Befehl für die Mehrebenenregression müssen wir nicht explizit angeben, dass es sich um eine Kontextvariable handelt. Wir ergänzen sie einfach in der Formel wie jede andere Variable auch.\n\nlibrary(lmerTest) \nmreg2 <- lmer(pol_vertrauen ~ 1 + bildung + \n                responsivitaet + zufr_wirtschaft + soz_vertrauen + \n                korruption +\n                (1 | cntry),  \n              data=ess)\n\nsummary(mreg2)\n\nLinear mixed model fit by REML. t-tests use Satterthwaite's method [\nlmerModLmerTest]\nFormula: pol_vertrauen ~ 1 + bildung + responsivitaet + zufr_wirtschaft +  \n    soz_vertrauen + korruption + (1 | cntry)\n   Data: ess\n\nREML criterion at convergence: 154608\n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-4.162 -0.657  0.012  0.646  5.391 \n\nRandom effects:\n Groups   Name        Variance Std.Dev.\n cntry    (Intercept) 0.127    0.357   \n Residual             2.784    1.669   \nNumber of obs: 39998, groups:  cntry, 25\n\nFixed effects:\n                   Estimate  Std. Error          df t value\n(Intercept)         4.32173     0.19373    23.15747   22.31\nbildung            -0.02499     0.00486 39991.73816   -5.14\nresponsivitaet      0.84524     0.01142 39991.67508   74.04\nzufr_wirtschaft     0.31270     0.00439 39865.03534   71.23\nsoz_vertrauen       0.21016     0.00499 39991.84797   42.08\nkorruption         -0.01176     0.00539    23.23182   -2.18\n                            Pr(>|t|)    \n(Intercept)     < 0.0000000000000002 ***\nbildung                   0.00000027 ***\nresponsivitaet  < 0.0000000000000002 ***\nzufr_wirtschaft < 0.0000000000000002 ***\nsoz_vertrauen   < 0.0000000000000002 ***\nkorruption                     0.039 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) bildng rspnsv zfr_wr sz_vrt\nbildung      0.002                            \nresponsivtt -0.021 -0.177                     \nzfr_wrtschf -0.034 -0.011 -0.241              \nsoz_vertran -0.027 -0.104 -0.140 -0.230       \nkorruption  -0.929 -0.003  0.022  0.037  0.030\n\n\nWie wir bei den Fixed Effects sehen können, hat also Korruption einen kleinen, aber signifikanten negativen Effekt auf den variierenden Intercept. Also mit Zunahme der Korruption um einen Skalenpunkt sinkt das durchschnittliche politische Vertrauen in einem Land um \\(-0.012\\)\nDa der Korruptionsindex eine Skala von 0 bis 100 ist, ist das nicht wenig. Sehr korruptionsbelastete Länder haben einen Korruptionsindex von über 50. Am anderen Ende stehen Länder mit einem Wert von 15. Bei 35 Skalenpunkten Unterschied ergibt sich also für die abhängige Variable politisches Vertrauen einen Unterschied von \\(-0.412\\) Punkten.\nUnd was sagt die Modellgüte?\n\nmodel_performance(mreg2)\n\n# Indices of model performance\n\nAIC       |      AICc |       BIC | R2 (cond.) | R2 (marg.) |   ICC |  RMSE | Sigma\n-----------------------------------------------------------------------------------\n1.546e+05 | 1.546e+05 | 1.547e+05 |      0.471 |      0.446 | 0.044 | 1.668 | 1.669\n\n\nDas konditionale \\(R^2\\) erhöht sich minimal von 44.8 auf 47.1.\n\n\nSchluss\nDamit sind wir am Ende des vierten Videos.\nWir haben gesehen, wie man ein einfaches Mehrebenenmodell als Formel notiert und das Modell mit der lmer()-Funktion in R umsetzt.\nDabei haben wir zuerst ein variierendes Intercept Modell mit Prädiktoren auf Ebene 1 geschätzt und habe Kompositionseffekte kennengelernt. Danach haben wir das Modell um eine unabhängige Variable auf Ebene 2 ergänzt und interpretiert.\nIm nächsten Video 5 werden wir dann das Varying Slope Modell und das Modell mit Cross-Level Interaktion anschauen und klären, wie man herausfindet, welches Modell das passende ist.\nAm Ende dieses Videos gibt es noch eine Aufgabe und zum Schluss die Literatur.\n\n\nAufgabe\n\nRechnen Sie zu einer eigenen Fragestellung ein Mehrebenenmodell mit Prädiktoren auf Ebene 1. Prüfen Sie, wie stark Kompositionseffekte die Varianz auf Ebene 2 im Vergleich zum Nullmodell verringern.\nErgänzen Sie das Mehrebenenmodell um Prädiktoren auf Ebene 2. Wie viel Varianz können Sie auf den beiden Ebenen jeweils für sich genommen erklären?\n\n\n\nLernzielabgleich\nHaben Sie alles mitgenommen? Fragen Sie sich selbst, ob Sie die folgenden Lernziele erreicht haben:\n\nSie können ein einfaches Mehrebenenmodell als Formel ausdrücken.\nSie wissen, wie man das einfache Mehrebenenmodell in R umsetzt.\nSie kennen die relevanten Quantities of Interest und können sie interpretieren.\n\n\n\nLiteratur\n\nNakagawa, S.; Schielzeth, H. (2013): A general and simple method for obtaining R2 from generalized linear mixed-effects models. Methods in Ecology and Evolution, 4(2), 133–142. DOI: https://doi.org/10.1111/j.2041-210x.2012.00261.x\n\n\n\n\n\n\n\n\n\nFußnoten\n\n\nIn Teil 5 erweitern wir dann diese Modelle um variierenden Slopes und Cross-Level-Interaktionen.↩︎"
  },
  {
    "objectID": "mreg5.html#modellvergleich-mittels-anova",
    "href": "mreg5.html#modellvergleich-mittels-anova",
    "title": "5. Wie schätzt man variierende Slopes und Cross-Level Interaktionen?",
    "section": "Modellvergleich mittels Anova",
    "text": "Modellvergleich mittels Anova\nÜblicherweise vergleichen wir zwei Modelle mit der anova()-Funktion.\nDie Anova testet die Nullhypothese, dass die beiden Modelle gleich gut oder schlecht zu den Daten passen. Ist der Test signifikant, wird die Nullhypothese also zurückgewiesen, wissen wir, dass das eine Modell eine bessere Anpassung an die Daten hat.\nWerden zwei OLS Modelle verglichen, basiert die Anova auf einem F-Test der Fehlerqaudrate der beiden Modelle.\nFür Modelle die auf einem Maximum Likelihood Schätzer basieren- z.B. bei der logistischen Regression, aber auch das Mehrebenenmodell - dann nutzt die Anova einen \\(\\chi^2\\)-Test (Chi quadrat) auf Basis der Likelihood-Funktion der Modelle.\nLeider ist das bei Mehrebenenmodellen nicht ohne größere Vorsicht möglich.\nUnd um das zu verstehen müssen wir kurz über den Schätzalgorithmus sprechen.\nBisher haben wir unsere Mehrebenenregression mit der lmer()-Funktion geschätzt, ohne explizit anzugeben, welcher Schätzer genutzt werden soll.\nlmer() nutzt dabei als Voreinstellung automatisch den sogenannten REML-Schätzer (Restricted Maximum Likelihood).\nDer lmer() Befehl ergänzt also implizit REML=TRUE:\n\n# Nicht ausführen\nmreg <- lmer(y ~ 1 + x + (1 + grp), \n             data = df, \n             REML = TRUE)\n\nWenn man REML=FALSE angibt, wird statt des REML-Schätzers der einfache ML-Schätzer genutzt.\nDer ML-Schätzer wählt dabei diejenigen Werte für die Modellparameter, bei denen die Wahrscheinlichkeit (Likelihood) am größten ist, die Werte der Daten zu beobachten. Wähle das Modell, beim dem \\(p(Daten|Modell)\\) am größten ist.\nDabei können aber die Varianzparameter unterschätzt werden.\nBeim REML-Schätzer werden nur die Parameter der Varianzkomponenten, also die Random Effects des Modells über den ML-Schätzer gewählt. Die anderen Modellparamter werden als gegeben angenommen (sie werden zuvor automatisch separat geschätzt). Die Schätzung des REML Schätzers ist also restricted auf die Varianzkomponenten. Und soll dadurch e eine unverzerrte Schätzung der Varianzkomponenten erlauben.\nABER: Je größer die SP, desto weniger ist die Schätzung der Varianzkomponenten mittels ML-Schätzer verzerrt. Diese Eigenschaft ist dann wichtig, wenn Sie folgende Fehlermeldung bei der Schätzung ihres Modells erhalten. Dann lässt sich das Modell nicht mit dem REML Schätzer berechnen. Bei ausreichend größeren Fallzahlen können Sie versuchen, das Modell mit dem ML Schätzer zu fitten, also REML=FALSE.\nOK, kurz durchatmen, dann kommen wir zurück zur einfachen Anwendung.\nKommen wir zurück zum Modellvergleich mit der Anova.\nDurch die Eigenschaft der REML-Schätzung darf die log-Likelihood zwischen Modellen mit unterschiedlichen fixed Effects nicht verglichen werden - und damit darf auch die Devianz, also die Differenz zwischen zwei Modellen, nicht berechnet werden. Diese ist aber die Grundlage für den \\(\\chi^2\\)-Test der Anova.\nSollen zwei Modelle mit unterschiedlichen fixed Effects verglichen werden, müssen diese Modelle mit dem ML-Schätzer gefittet sein.\nDie Modelle mreg1 und mreg2 sind zwei Modelle, die sich nur hinsichtlich der fixed Effects unterscheiden. Aber wir hatten sie mit dem REML-Schätzer gefittet, da dieser ja die default Einstellung ist.\nWas passiert, wenn wir mit diesen Modellen die Anova rechnen?\n\n# Per default werden die Modelle mit ML refittet:\nanova(mreg1, mreg2)\n\nData: ess\nModels:\nmreg1: pol_vertrauen ~ 1 + bildung + responsivitaet + zufr_wirtschaft + soz_vertrauen + (1 | cntry)\nmreg2: pol_vertrauen ~ 1 + bildung + responsivitaet + zufr_wirtschaft + soz_vertrauen + korruption + (1 | cntry)\n      npar    AIC    BIC logLik deviance Chisq Df Pr(>Chisq)  \nmreg1    7 154581 154641 -77284   154567                      \nmreg2    8 154578 154647 -77281   154562  4.71  1       0.03 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#anova(mreg1, mreg2, refit=T)\n\nDie Anova schätzt automatisch beide Modelle erneut mit dem ML Schätzer. So können wir also direkt die Anova interpretieren:\nModell 2 ist also signifikant besser an die Daten angepasst als Modell 1.\nUnd was ist mit dem Vergleich von mreg2 und mreg3? Hier unterscheiden sich die random Effects, die fixed Effects sind aber identisch spezifiziert. Wir müssen also beide Modelle mit dem REML-Schätzer vergleichen.\nAuch hier würde die Anova mit dem ML-Schätzer refitten. Dann dürften wir die Anova aber nicht interpretieren. Wir müssen der Anova also sagen, dass sie nicht refitten soll: das geschieht mit dem Argument refit=FALSE:\n\nanova(mreg2, mreg3, refit=F)\n\nData: ess\nModels:\nmreg2: pol_vertrauen ~ 1 + bildung + responsivitaet + zufr_wirtschaft + soz_vertrauen + korruption + (1 | cntry)\nmreg3: pol_vertrauen ~ 1 + bildung + responsivitaet + zufr_wirtschaft + soz_vertrauen + korruption + (1 + bildung | cntry)\n      npar    AIC    BIC logLik deviance Chisq Df        Pr(>Chisq)    \nmreg2    8 154624 154693 -77304   154608                               \nmreg3   10 154568 154654 -77274   154548    60  2 0.000000000000093 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAuch hier sehen wir, dass die log-Likelihood im zweiten Modell geringer ist - also besser ist - und zwar so viel, dass der \\(\\chi^2\\)-Test bei zwei Freiheitsgraden signifikant ist. mreg3 ist also signifikant besser alsmreg2 - wir haben also signifikante Varianz im random Slope für Bildung und können das Modell nun auch inhaltlich interpretieren!"
  },
  {
    "objectID": "mreg5.html#interpretation-des-varying-slope-modells",
    "href": "mreg5.html#interpretation-des-varying-slope-modells",
    "title": "5. Wie schätzt man variierende Slopes und Cross-Level Interaktionen?",
    "section": "Interpretation des Varying Slope Modells",
    "text": "Interpretation des Varying Slope Modells\nDer Fixed Effect für Bildung sagt uns nun wie groß der durchschnittliche Bildungseffekt \\(\\gamma_{10}\\) ist: \\(-0.033\\). Dieser Effekt ist signifikant. Also haben wir über alle Länder hinweg einen leicht negativen Effekt für Bildung.\nInteressant ist nun aber, wie stark sich die Effekte zwischen den Länder unterscheiden. Denn: wir haben ja einen variierenden Effekt, dessen Varianz bei \\(0.002\\) liegt!\nMit der Funktion ranef() können wir uns Ausgeben lassen, wie stark die Länder vom durchschnittliche Bildungseffekt, dem fixed Effect \\(\\gamma_{10}\\) abweichen:\n\nranef(mreg3)\n\n$cntry\n   (Intercept)  bildung\nAT     -0.1319 -0.04009\nBE      0.3412  0.01361\nBG     -0.1306 -0.06326\nCH      0.1159 -0.04039\nCY     -0.0209 -0.07355\nCZ     -0.3222 -0.03894\nDE     -0.4280  0.01240\nEE      0.1487  0.02992\nES     -0.3056  0.01687\nFI      0.3602  0.04636\nFR      0.2671  0.02568\nGB     -0.2287  0.06221\nHR     -0.4182 -0.02260\nHU      0.7530 -0.01809\nIE     -0.0763  0.02471\nIT      0.4765  0.04142\nLT     -0.2662 -0.02655\nLV     -0.2626 -0.00636\nNL      0.5076  0.05266\nNO      0.2414  0.02780\nPL     -0.4717 -0.07547\nPT     -0.1912  0.04102\nSE      0.3093  0.07651\nSI     -0.5424 -0.04742\nSK      0.2760 -0.01844\n\nwith conditional variances for \"cntry\" \n\n\nTatsächlich reichen diese Abweichungen von \\(-0.075\\) bis \\(0.077\\).\nUm das anschaulicher zu machen, addieren wir den fixed Effect für Bildung.\n\nre_bildung <- ranef(mreg3)$cntry[,2]\nnames(re_bildung) <- row.names(ranef(mreg3)$cntry)\n\n#re_bildung+fixef(mreg2)[2]\nsort(re_bildung+fixef(mreg2)[2])\n\n       PL        CY        BG        SI        CH        AT        CZ        LT \n-0.100462 -0.098543 -0.088252 -0.072407 -0.065380 -0.065079 -0.063930 -0.051539 \n       HR        SK        HU        LV        DE        BE        ES        IE \n-0.047593 -0.043436 -0.043086 -0.031350 -0.012589 -0.011378 -0.008124 -0.000284 \n       FR        NO        EE        PT        IT        FI        NL        GB \n 0.000690  0.002807  0.004929  0.016026  0.016428  0.021372  0.027672  0.037216 \n       SE \n 0.051515 \n\n\nAddiert man also zu den jeweiligen random Effects für Bildung je Land den fixed Effect für Bildung \\(\\gamma_{10}\\) zeigt sich, das der variierende Slope für Bildung \\(\\beta_{1j}\\) von \\(-0.1\\) in Polen PL bis \\(0.052\\) in Schweden SE reicht."
  },
  {
    "objectID": "mreg6.html",
    "href": "mreg6.html",
    "title": "6. Wie lassen sich die Ergebnisse einer Mehrebenregression berichten?",
    "section": "",
    "text": "Themenüberblick\nIn diesem Teil sechs beschäftigen wir uns mit der Frage: Wie lassen sich die Ergebnisse einer Mehrebenregression berichten?\nIn den vergangenen Teilen 4 und 5 haben wir nacheinander verschiedene Varianten des Mehrebenenmodells geschätzt und interpretiert. Mithilfe der Anova haben wir geprüft, ob die aufeinander aufbauenden Modelle jeweils besser an die Daten angepast ist.\nIn diesem Teil wird es darum gehen, wie man die Ergebnisse dieser Modelle berichtet und wie man die relevanten Quantites of Interest grafisch aufbereitet.\nDie konkreten Lernziele sind, dass Sie mit R in der Lage sind…\n\ndie Regressionsergebnisse tabellarisch gegenüberzustellen.\ndie fixed Effects als Forrestplot grafisch darzustellen.\ndie variierenden Intercepts und variierende Slopes grafisch darzustellen.\nCross-Level Interaktionen mit Effekt-Plots grafisch darzustellen.\n\nDazu wechseln wir nun zu R.\n\n\nVorbereitung der Daten und Modelle\nWie auch schon zuvor, müssen wir das komplette RScript aus dem vorigen Teil 5 mit der source()-Funktion ausühren, um die Daten zu laden (RScript_mreg5.R bei den Ressourcen).\n\nsource(\"./Ressourcen/RScript_mreg5.R\") #Pfad zur Datei ggf. anpassen\n\n\n\nTabellen zu den Regressionsmodellen\nUm die Ergebnisse der Regressionen tabellarisch aufzubereiten, nutzen wir das texreg-Paket.\nDas Paket enthält mehrere Funktionen, um die Ergebnisse unterschiedlicher Regressionsmodelle automatisch aufzubereiten und als Tabelle auszugeben.\nDabei unterscheiden sich die Funktionen, je nach dem, in welchem Format die Tabellen formatiert werden sollen:\n\nscreenreg() gibt die Tabelle auf dem Bildschirm in der RConsole aus.\n\n\nlibrary(texreg)\nscreenreg(list(mreg3,mreg4))\n\n\n============================================================\n                                Model 1        Model 2      \n------------------------------------------------------------\n(Intercept)                          4.14 ***       4.31 ***\n                                    (0.19)         (0.19)   \nbildung                             -0.03 **        0.04    \n                                    (0.01)         (0.02)   \nresponsivitaet                       0.84 ***       0.84 ***\n                                    (0.01)         (0.01)   \nzufr_wirtschaft                      0.31 ***       0.31 ***\n                                    (0.00)         (0.00)   \nsoz_vertrauen                        0.21 ***       0.21 ***\n                                    (0.00)         (0.00)   \nkorruption                          -0.01          -0.01 *  \n                                    (0.01)         (0.01)   \nbildung:korruption                                 -0.00 ** \n                                                   (0.00)   \n------------------------------------------------------------\nAIC                             154568.42      154574.58    \nBIC                             154654.39      154669.14    \nLog Likelihood                  -77274.21      -77276.29    \nNum. obs.                        39998          39998       \nNum. groups: cntry                  25             25       \nVar: cntry (Intercept)               0.13           0.13    \nVar: cntry bildung                   0.00           0.00    \nCov: cntry (Intercept) bildung       0.01           0.00    \nVar: Residual                        2.78           2.78    \n============================================================\n*** p < 0.001; ** p < 0.01; * p < 0.05\n\n\n\nwordreg() erstellt die Tabelle in einem Microsoft Word Format. Dafür muss nur die Zieldatei als file-Argument angegeben werden.\n\n\nwordreg(list(mreg3,mreg4),\n        file = \"./Docs/tabelle.doc\")\n\nAber der Königsweg ist natürlich, die Tabellen über RMarkdown direkt in html- oder Latex-Dokumenten erstellen zu lassen.\n\nhtmlreg() erstellt die Tabelle im html-Format.\ntexreg() gibt die Tabelle im Latex Format aus.\n\nAuch dieses Dokument wurde mit RMarkdown erstellt, wir können hier also die Tabellenausgabe des Aufrufs htmlreg() sehen:\n\nhtmlreg(list(mreg3,mreg4))\n\n\n\nStatistical models\n\n\n\n\n \n\n\nModel 1\n\n\nModel 2\n\n\n\n\n\n\n(Intercept)\n\n\n4.14***\n\n\n4.31***\n\n\n\n\n \n\n\n(0.19)\n\n\n(0.19)\n\n\n\n\nbildung\n\n\n-0.03**\n\n\n0.04\n\n\n\n\n \n\n\n(0.01)\n\n\n(0.02)\n\n\n\n\nresponsivitaet\n\n\n0.84***\n\n\n0.84***\n\n\n\n\n \n\n\n(0.01)\n\n\n(0.01)\n\n\n\n\nzufr_wirtschaft\n\n\n0.31***\n\n\n0.31***\n\n\n\n\n \n\n\n(0.00)\n\n\n(0.00)\n\n\n\n\nsoz_vertrauen\n\n\n0.21***\n\n\n0.21***\n\n\n\n\n \n\n\n(0.00)\n\n\n(0.00)\n\n\n\n\nkorruption\n\n\n-0.01\n\n\n-0.01*\n\n\n\n\n \n\n\n(0.01)\n\n\n(0.01)\n\n\n\n\nbildung:korruption\n\n\n \n\n\n-0.00**\n\n\n\n\n \n\n\n \n\n\n(0.00)\n\n\n\n\nAIC\n\n\n154568.42\n\n\n154574.58\n\n\n\n\nBIC\n\n\n154654.39\n\n\n154669.14\n\n\n\n\nLog Likelihood\n\n\n-77274.21\n\n\n-77276.29\n\n\n\n\nNum. obs.\n\n\n39998\n\n\n39998\n\n\n\n\nNum. groups: cntry\n\n\n25\n\n\n25\n\n\n\n\nVar: cntry (Intercept)\n\n\n0.13\n\n\n0.13\n\n\n\n\nVar: cntry bildung\n\n\n0.00\n\n\n0.00\n\n\n\n\nCov: cntry (Intercept) bildung\n\n\n0.01\n\n\n0.00\n\n\n\n\nVar: Residual\n\n\n2.78\n\n\n2.78\n\n\n\n\n\n\n***p < 0.001; **p < 0.01; *p < 0.05\n\n\n\n\n\n\nDamit Sie auch den passenden Markdown Code-Chunk sehen, probieren wir das kurz aus…\nDieses Code-Snippet kopiere ich in ein RMarkdown-Dokument, das ich dann als html oder als pdf-Datei knitten kann. Wichtig ist, das das Code-Chunk Argument results='asis' angegeben wird.\n\n#```{r, results='asis'}\nsource(\"./RScript_mreg5.R\")\nlibrary(texreg)\nhtmlreg(list(mreg3,mreg4))\ntexreg(list(mreg3,mreg4))\n#```\n\nAbgesehen vom texreg-Paket kann man altrenativ die tab_model()-Funktion aus dem sjPlot-Paket nutzen. Auch diese Funktion erstellt für unterschiedlichste Regressionsmodelle die passenden Tabellen. Zudem lassen sich die Tabellen sehr kleinteilig den eigenen Bedürfnissen anpassen.\nHilfe und Erläuterungen gibt es auch in der Vignette zum Paket: https://strengejacke.github.io/sjPlot/articles/tab_mixed.html\n\nlibrary(sjPlot)\n#?tab_model\n# Gibt Tabelle im RStudio Viewer aus\ntab_model(mreg0, mreg3,mreg4, \n          p.style = \"stars\",\n          use.viewer = T)\n\n\n\n\n \npol_vertrauen\npol_vertrauen\npol_vertrauen\n\n\nPredictors\nEstimates\nCI\nEstimates\nCI\nEstimates\nCI\n\n\n(Intercept)\n3.89 ***\n3.48 – 4.31\n4.14 ***\n3.78 – 4.51\n4.31 ***\n3.93 – 4.68\n\n\nbildung\n\n\n-0.03 **\n-0.05 – -0.01\n0.04 \n-0.01 – 0.09\n\n\nresponsivitaet\n\n\n0.84 ***\n0.82 – 0.87\n0.84 ***\n0.82 – 0.86\n\n\nzufr wirtschaft\n\n\n0.31 ***\n0.30 – 0.32\n0.31 ***\n0.30 – 0.32\n\n\nsoz vertrauen\n\n\n0.21 ***\n0.20 – 0.22\n0.21 ***\n0.20 – 0.22\n\n\nkorruption\n\n\n-0.01 \n-0.02 – 0.00\n-0.01 *\n-0.02 – -0.00\n\n\nbildung * korruption\n\n\n\n\n-0.00 **\n-0.00 – -0.00\n\n\nRandom Effects\n\n\n\nσ2\n4.26\n2.78\n2.78\n\n\n\nτ00\n1.11 cntry\n0.13 cntry\n0.13 cntry\n\n\nτ11\n \n0.00 cntry.bildung\n0.00 cntry.bildung\n\n\nρ01\n \n0.38 cntry\n0.34 cntry\n\n\nICC\n0.21\n0.05\n0.05\n\n\nN\n25 cntry\n25 cntry\n25 cntry\n\nObservations\n39998\n39998\n39998\n\n\nMarginal R2 / Conditional R2\n0.000 / 0.207\n0.433 / 0.460\n0.446 / 0.471\n\n\n* p<0.05   ** p<0.01   *** p<0.001\n\n\n\n\n\n\nOder man kann die Tabelle in einer Datei speichern:\n\ntab_model(mreg0, mreg3, mreg4, \n          p.style = \"stars\",\n          use.viewer = F,\n          file = \"./Docs/tabelle.html\")\n\n\n\n\n \npol_vertrauen\npol_vertrauen\npol_vertrauen\n\n\nPredictors\nEstimates\nCI\nEstimates\nCI\nEstimates\nCI\n\n\n(Intercept)\n3.89 ***\n3.48 – 4.31\n4.14 ***\n3.78 – 4.51\n4.31 ***\n3.93 – 4.68\n\n\nbildung\n\n\n-0.03 **\n-0.05 – -0.01\n0.04 \n-0.01 – 0.09\n\n\nresponsivitaet\n\n\n0.84 ***\n0.82 – 0.87\n0.84 ***\n0.82 – 0.86\n\n\nzufr wirtschaft\n\n\n0.31 ***\n0.30 – 0.32\n0.31 ***\n0.30 – 0.32\n\n\nsoz vertrauen\n\n\n0.21 ***\n0.20 – 0.22\n0.21 ***\n0.20 – 0.22\n\n\nkorruption\n\n\n-0.01 \n-0.02 – 0.00\n-0.01 *\n-0.02 – -0.00\n\n\nbildung * korruption\n\n\n\n\n-0.00 **\n-0.00 – -0.00\n\n\nRandom Effects\n\n\n\nσ2\n4.26\n2.78\n2.78\n\n\n\nτ00\n1.11 cntry\n0.13 cntry\n0.13 cntry\n\n\nτ11\n \n0.00 cntry.bildung\n0.00 cntry.bildung\n\n\nρ01\n \n0.38 cntry\n0.34 cntry\n\n\nICC\n0.21\n0.05\n0.05\n\n\nN\n25 cntry\n25 cntry\n25 cntry\n\nObservations\n39998\n39998\n39998\n\n\nMarginal R2 / Conditional R2\n0.000 / 0.207\n0.433 / 0.460\n0.446 / 0.471\n\n\n* p<0.05   ** p<0.01   *** p<0.001\n\n\n\n\n\n\n\n\nGrafische Darstellung der Ergebnisse\nDas Schweizer Taschenmesser der grafischen Darstellung von Regressionsergebnissen ist das schon genannte Paket sjPlot.\nDie Darstellung der fixed Effects erfolgt wie bei ganz gewöhnlichen Regressionsmodellen. Um die fixed Effects grafisch darszustellen nutze ich die Funktion plot_model():\n\nlibrary(sjPlot)\nplot_model(mreg4,\n           show.values=T)\n\n\n\n\n\n\n\n\nDiese Darstellung lässt sich noch durch zahlreiche Optionen anpassen und verschönern. Das ist aber nicht mehr Teil dieser Videoserie.\nWenn wir mehrere Modelle vergleichen wollen, nutzen wir die Funktion plot_models() (das Plural-s macht den Unterschied).\n\nlibrary(sjPlot)\nplot_models(mreg3, mreg4,\n           show.values=T)\n\n\n\n\n\n\n\n\nplot_models hat aber auch Mehrebenenmodell-spezifische Optionen. Ich empfehle auf jeden Fall einen Blick in die Dokumentation:\nhttps://strengejacke.github.io/sjPlot\nUm einen Eindruck von den random Effects zu bekommen, also von den variierenden Intercepts und variierenden Slopes kann man der Funktion plot_model() mit dem argument type=\"re\" sagen, dass die random effects dargestellt werden sollen.\n\nplot_model(mreg4, type=\"re\")\n\n\n\n\n\n\n\n\nWenn ein Modell mehr als einen Random Effect aufweist, kann man mit sort.est angeben, nach welchem Effekt sortiert werden soll.\n\nplot_model(mreg4, type=\"re\", sort.est = \"bildung\")\n\n\n\n\n\n\n\nplot_model(mreg4, type=\"re\", sort.est = \"(Intercept)\")\n\n\n\n\n\n\n\n\nSchließlich kann der Cross-Level Interaktionseffekt dargestellt werden, indem man als type=\"int\" spezifiziert.\n\nplot_model(mreg4, type=\"int\")\n\n\n\n\n\n\n\n\nHier sieht man sehr anschaulich, was der Interaktionseffekt von \\(-0.002\\) bedeutet.\nWie auch im Forrest Plot oder in der Tabelle ausgegeben sehen wir auch hier, dass der Effekt von Bildung nicht signifikant ist - und zwar für Länder, die sehr sauber sind.\nDer in der Tabelle berichtete Effekt für Bildung ist ja der Effekt, den wir für Länder schätzen, deren Wert für korruption bei \\(0\\) liegt. Empirisch ist dieser Wert nicht vorhanden. Das sauberste Land hat einen Wert von \\(15\\). Das sehen wir hier auch in der Grafik. Die rote Linie gibt den Effekt für Bildung wieder, den dieses am wenigsten Korrupte Land aufweist. Zwar ist die Linie leicht ansteigend, da aber das Konfindenzband so breit ist, dass Anfang und Ende der Linie auf der jeweils gegenüberliegenden Seite immernoch innerhalb des Konfindenzbandes liegen wissen wir, dass der Effekt nicht signifikant ist.\nAnders bei Ländern mit den höchsten Wert auf dem Korruptionsindex. Hier sehen wir einen negativen Effekt. Je höher die Bildung, desto geringer ist das beobachtete Niveau an politischem Vertrauen.\nNatürlich gibt es für die Zwischenschritte von Korruption auch die jeweiligen Slopes für Bildung. Das lässt sich aber grafisch dann nicht überischtlich darstellen.\nZwar sind die Konfindenzbänder für beide Linien relativ zur Effektgröße recht breit. Dennoch sehen wir schon bei wenig über dem Minimum liegenden Werten von Bildung, dass sich die Konfidenzbänder einseitig nicht überschneiden, also signifikante Unteschiede zwischen den unterschiedlich korruptionsbelasteten Ländern bestehen.\nInhaltlich ist das ein interessantes Ergebnis: Zunächst schien es, dass Bildung negativ auf politisches Vertrauen wirkt. Bei genauerem Hinsehen zeigt sich, dass der Effekt von Bildung varriert. In Ländern mit geringer Korruption hat Bildung keinen Einfluss. Mit zunehmender Korruption zeigt sich, dass Menschen mit höherer Bildung weniger Vertrauen. Für Menschen mit weniger Bildung, zeigt sich jedoch kein Unterschied.\n\n\nSchluss\nDamit sind wir am Ende des letzten Teils der Videoreihe Mehrebenenregression in R.\nSie wissen nun, was eine Mehrebenenregression ist. Sie können beurteilen, wann eine Mehrebenenrgression notwendig ist, sie kennen die verschiedenen Varianten und können diese mit R rechnen und entscheiden, welches Modell das passende ist. Und Sie können die Ergebnisse tabellarisch und mit Grafiken aufbereiten.\nFür die praktische Anwendung sind Sie bereits gut gerüstet. Trotzdem lassen sich zahlreiche Aspekte vertiefen. So können Sie sich zum Beispiel noch mit der Regressionsdiagnostik in Mehrebenenmodellen vertraut machen (z.B. mit dem Paket HLMdiag oder dem Paket DHARMa). Oder Sie können Generalsierte Mehrebenenmodelle betrachten, die dann für nicht-metrische abhängige Variablen geeignet sind.\nWenn Sie die Mehrebenenregression von Grundauf verstehen möchsten, dann empfehle ich Ihnen das Buch Raudenbush & Bryk (2002): Hierarchical Linear Models Applications and Data Analysis Methods. Sage.\nAm Ende des Videos gibt es wie immer noch eine kleine Aufgabe.\n\n\nAufgabe\n\nStellen Sie zu Ihrer eigenen Fragestellung die Regressionsergebnisse der verschiedenen Modelle vergleichend als Tabelle dar.\nBereiten Sie die Quantites of Interest der Mehrebenenmodelle (Variierende Intercepts, variierende Slopes, Cross-Level Interaktionseffekte) grafisch auf.\n\n\n\nLernzielabgleich\nHaben Sie alles mitgenommen? Fragen Sie sich selbst, ob Sie die folgenden Lernziele erreicht haben:\n\ndie Regressionsergebnisse tabellarisch gegenüberzustellen.\ndie fixed Effects als Forrestplot grafisch darzustellen.\ndie variierenden Intercepts und variierende Slopes grafisch darzustellen.\nCross-Level Interaktionen mit Effekt-Plots grafisch darzustellen."
  },
  {
    "objectID": "ressourcen.html",
    "href": "ressourcen.html",
    "title": "Ressourcen",
    "section": "",
    "text": "Daten\n\n ess2018_macro.csv\n\n\n\nRScript Dateien\n\n RScript_mreg1.R\n RScript_mreg2a.R\n RScript_mreg2b.R\n RScript_mreg3.R\n RScript_mreg4.R\n RScript_mreg5.R\n RScript_mreg6.R"
  }
]